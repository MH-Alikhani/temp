{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "text"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        @font-face {\n",
       "            /* تعریف نام فونت */\n",
       "            font-family: 'BZar';\n",
       "            /* اکسپلورر 9 به بعد */\n",
       "            src: url('font/BZar.eot');\n",
       "            /* بررسی نصب بودن فونت در سیستم کاربر */\n",
       "            src: local('bZar'),\n",
       "                 /* برای برخی از مرورگرها مانند سافاری */\n",
       "                 local('b Zar'),\n",
       "                 /* هک برای اکسپلورر 8 و ماقبل */\n",
       "                 url('font/BZar.eot?#iefix') format('embedded-opentype'),\n",
       "                 /* فرمت مناسب مرورگرهای خیلی جدید */\n",
       "                 url('font/BZar.woff2') format('woff2'),\n",
       "                 /* فرمت مناسب مرورگرهای تقریبا جدید */\n",
       "                 url('font/BZar.woff') format('woff'),\n",
       "                 /* تمام مرورگرها به جزء اکسپلورر */\n",
       "                 url('font/BZar.ttf') format('truetype'),\n",
       "                 /* نسخه‌های قدیمی سیستم عامل iOS */\n",
       "                 url('font/BZar.svg#BZar') format('svg');\n",
       "            font-style: normal;\n",
       "            font-weight: normal;\n",
       "            font-display: swap;\n",
       "        }\n",
       "    \n",
       "    \n",
       "        .reveal .slides {\n",
       "            direction: ltr;\n",
       "            text-align: right;\n",
       "        }\n",
       "        \n",
       "        div {\n",
       "            direction: ltr;\n",
       "            text-align: left;\n",
       "        }\n",
       "        \n",
       "        p > img {\n",
       "          display: block;\n",
       "          margin-left: auto;\n",
       "          margin-right: auto;\n",
       "          max-width:75%; \n",
       "          height:auto;\n",
       "        }\n",
       "        \n",
       "        div.text_cell_render.rendered_html > *, li > p, .rendered_html p, #quarto-document-content > *\n",
       "        {\n",
       "            direction: ltr;\n",
       "            text-align: left;\n",
       "            font-family: BZar, Tahoma, Geneva, sans-serif;\n",
       "            font-size: x-large;\n",
       "            line-height: 26pt;\n",
       "        }\n",
       "        \n",
       "        .jp-CodeMirrorEditor .jp-Editor .jp-InputArea-editor {\n",
       "            direction: ltr !important;\n",
       "        }\n",
       "        \n",
       "        .CodeMirror-lines .output_subarea .output_text .output_stream .output_stdout{\n",
       "            direction: ltr !important;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "def f():\n",
    "    return HTML(\"\"\"\n",
    "    <style>\n",
    "        @font-face {\n",
    "            /* تعریف نام فونت */\n",
    "            font-family: 'BZar';\n",
    "            /* اکسپلورر 9 به بعد */\n",
    "            src: url('font/BZar.eot');\n",
    "            /* بررسی نصب بودن فونت در سیستم کاربر */\n",
    "            src: local('bZar'),\n",
    "                 /* برای برخی از مرورگرها مانند سافاری */\n",
    "                 local('b Zar'),\n",
    "                 /* هک برای اکسپلورر 8 و ماقبل */\n",
    "                 url('font/BZar.eot?#iefix') format('embedded-opentype'),\n",
    "                 /* فرمت مناسب مرورگرهای خیلی جدید */\n",
    "                 url('font/BZar.woff2') format('woff2'),\n",
    "                 /* فرمت مناسب مرورگرهای تقریبا جدید */\n",
    "                 url('font/BZar.woff') format('woff'),\n",
    "                 /* تمام مرورگرها به جزء اکسپلورر */\n",
    "                 url('font/BZar.ttf') format('truetype'),\n",
    "                 /* نسخه‌های قدیمی سیستم عامل iOS */\n",
    "                 url('font/BZar.svg#BZar') format('svg');\n",
    "            font-style: normal;\n",
    "            font-weight: normal;\n",
    "            font-display: swap;\n",
    "        }\n",
    "    \n",
    "    \n",
    "        .reveal .slides {\n",
    "            direction: ltr;\n",
    "            text-align: right;\n",
    "        }\n",
    "        \n",
    "        div {\n",
    "            direction: ltr;\n",
    "            text-align: left;\n",
    "        }\n",
    "        \n",
    "        p > img {\n",
    "          display: block;\n",
    "          margin-left: auto;\n",
    "          margin-right: auto;\n",
    "          max-width:75%; \n",
    "          height:auto;\n",
    "        }\n",
    "        \n",
    "        div.text_cell_render.rendered_html > *, li > p, .rendered_html p, #quarto-document-content > *\n",
    "        {\n",
    "            direction: ltr;\n",
    "            text-align: left;\n",
    "            font-family: BZar, Tahoma, Geneva, sans-serif;\n",
    "            font-size: x-large;\n",
    "            line-height: 26pt;\n",
    "        }\n",
    "        \n",
    "        .jp-CodeMirrorEditor .jp-Editor .jp-InputArea-editor {\n",
    "            direction: ltr !important;\n",
    "        }\n",
    "        \n",
    "        .CodeMirror-lines .output_subarea .output_text .output_stream .output_stdout{\n",
    "            direction: ltr !important;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\")\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <link rel=\"stylesheet\" href=\"css/jquery.jqZoom.css\" />\n",
       "    <script src=\"js/jquery-1.12.4.min.js\"></script>\n",
       "    <script src=\"js/jquery.zoom.min.js\"></script>\n",
       "    <script>\n",
       "        $(document).ready(function(){\n",
       "            $(\"img\").children().off();\n",
       "            $('img')\n",
       "            .wrap('<span style=\"display:inline-block\"></span>')\n",
       "            .css('display', 'block')\n",
       "            .parent()\n",
       "            .zoom({ on:'grab', duration: 150, magnify: 1 });\n",
       "        });\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "def g():\n",
    "    return HTML(\"\"\"\n",
    "    <link rel=\"stylesheet\" href=\"css/jquery.jqZoom.css\" />\n",
    "    <script src=\"js/jquery-1.12.4.min.js\"></script>\n",
    "    <script src=\"js/jquery.zoom.min.js\"></script>\n",
    "    <script>\n",
    "        $(document).ready(function(){\n",
    "            $(\"img\").children().off();\n",
    "            $('img')\n",
    "            .wrap('<span style=\"display:inline-block\"></span>')\n",
    "            .css('display', 'block')\n",
    "            .parent()\n",
    "            .zoom({ on:'grab', duration: 150, magnify: 1 });\n",
    "        });\n",
    "    </script>\n",
    "    \"\"\")\n",
    "\n",
    "g()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"فصل ششم\"\n",
    "format: \n",
    "  docx:\n",
    "    toc: true\n",
    "    section-numbers: true\n",
    "    highlight-style: github\n",
    "    dir: rtl\n",
    "#  pptx:\n",
    "#    toc: true\n",
    "#    execute:\n",
    "#      echo: false\n",
    "#      warning: false\n",
    "  html:\n",
    "    css: css/style.css \n",
    "    code-fold: false \n",
    "    echo: true \n",
    "    self-contained: false \n",
    "    lang: fa\n",
    "#  revealjs: \n",
    "#    incremental: true\n",
    "#    dir: rtl \n",
    "#  pdf:\n",
    "#    number-sections: true\n",
    "#    colorlinks: true\n",
    "#    pdf-engine: xelatex\n",
    "#    keep-tex: true\n",
    "page-layout: full\n",
    "toc: false \n",
    "dir: rtl  \n",
    "lang: fa  \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Keras: A deep dive\n",
    "This chapter covers:\n",
    "- Creating Keras models with \n",
    "    - the Sequential class, \n",
    "    - the Functional API, \n",
    "    - model subclassing \n",
    "- Using built-in Keras training and evaluation loops\n",
    "- Using Keras callbacks to customize training\n",
    "- Using TensorBoard to monitor training and evaluation metrics \n",
    "- Writing training and evaluation loops from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A spectrum of workflows\n",
    "- From beginner to expert\n",
    "- Principle of **progressive disclosure of complexity**:\n",
    "  - make it easy to get started, yet \n",
    "  - make it possible to handle high-complexity use cases, \n",
    "  - incremental learning at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to build Keras models\n",
    "There are three APIs for building models in Keras:\n",
    "1. The Sequential model: \n",
    "   1. the most approachable API,\n",
    "   2. it’s basically a Python list, \n",
    "   3. it’s limited to simple stacks of layers.\n",
    "2. The Functional API\n",
    "   1. focuses on graph-like model architectures,\n",
    "   2. It represents a nice mid-point between usability and flexibility,\n",
    "   3. it’s the most commonly used model-building API.\n",
    "3. Model subclassing\n",
    "   1. a low-level option\n",
    "   2. you write everything yourself from scratch\n",
    "   3. full control over every little thing\n",
    "   4. you won’t get access to many built-in Keras features\n",
    "   5. you will be more at risk of making mistakes.\n",
    "\n",
    "![Progressive disclosure of complexity for model building](img/07-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Sequential model\n",
    "The simplest way to build a Keras model is to use the Sequential model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build the same model incrementally via the add() method.\n",
    "\n",
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights get created after the first call:\n",
    "- until the input shape is known, they can’t be created.\n",
    "- model.weights produces errors\n",
    "- Use the build method.\n",
    "\n",
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_4/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.254811  ,  0.0284014 , -0.00241974,  0.19567803,  0.03954667,\n",
       "          0.03717914,  0.13251492, -0.01390034,  0.00830227, -0.16948503,\n",
       "          0.2557441 , -0.08849308, -0.22104861, -0.08763076,  0.29221654,\n",
       "         -0.24492195, -0.06238812,  0.26881206,  0.08769348,  0.2205401 ,\n",
       "          0.25503016, -0.28262892,  0.18333957,  0.05614978,  0.15084872,\n",
       "         -0.0035992 , -0.14476122, -0.0936328 , -0.21147227,  0.15010521,\n",
       "          0.18293145,  0.12450725, -0.10194163, -0.27410427, -0.01977229,\n",
       "         -0.17940982,  0.07584602,  0.20612901, -0.05969654, -0.283991  ,\n",
       "          0.06296048, -0.19124714, -0.25661865,  0.23490256, -0.2541374 ,\n",
       "          0.02233195,  0.06166652, -0.06999825,  0.26454008,  0.07466573,\n",
       "         -0.05951874, -0.00213644, -0.25435394, -0.15478683,  0.2927668 ,\n",
       "          0.15829104,  0.05029744,  0.15044233, -0.01697913, -0.15490875,\n",
       "          0.03341493, -0.17419276, -0.03047571,  0.09327307],\n",
       "        [-0.02529195, -0.11478588, -0.07607834,  0.048816  , -0.09976211,\n",
       "         -0.02695414,  0.15418792,  0.26366985,  0.08461699,  0.08195302,\n",
       "         -0.01961762, -0.0691261 ,  0.01077288, -0.04016119,  0.02527583,\n",
       "         -0.09849206, -0.25354886,  0.02065837, -0.295517  ,  0.03203014,\n",
       "          0.09885713,  0.02908078,  0.18564722,  0.24799263,  0.14603671,\n",
       "          0.13296884,  0.17428729, -0.2524892 ,  0.23142403, -0.22038008,\n",
       "         -0.117192  , -0.28136706, -0.26904887, -0.13000771, -0.03168997,\n",
       "          0.23549116,  0.22221929,  0.20854521,  0.10891584,  0.09915388,\n",
       "          0.2254551 , -0.20710354,  0.2169562 , -0.21197993, -0.13462846,\n",
       "          0.01098835,  0.01577955,  0.19985157,  0.03377995,  0.25606477,\n",
       "         -0.21252237,  0.0526883 ,  0.06059101, -0.03580329, -0.2847558 ,\n",
       "          0.08105618,  0.17944843, -0.03920862, -0.05563837, -0.15226233,\n",
       "          0.235192  , -0.0148927 ,  0.04631576,  0.13866523],\n",
       "        [-0.21886986, -0.2901575 ,  0.09262252, -0.28394514,  0.05903059,\n",
       "         -0.12161976, -0.1204956 ,  0.02085912, -0.02856287, -0.1531342 ,\n",
       "         -0.19020334, -0.19286709, -0.12012503,  0.17264086, -0.17147006,\n",
       "         -0.06787217,  0.03137189, -0.04041624, -0.19517574, -0.22937778,\n",
       "          0.15794453,  0.27339596,  0.26489323, -0.25890476, -0.09065518,\n",
       "          0.22652388, -0.2421636 , -0.26782492, -0.13589166, -0.2251099 ,\n",
       "          0.23927647,  0.20504612,  0.00470635, -0.19168957,  0.14746028,\n",
       "         -0.13858418,  0.18466818, -0.00141853,  0.10319036, -0.08833718,\n",
       "          0.23962855, -0.29020175, -0.08057979, -0.24471983, -0.04719725,\n",
       "         -0.13908146, -0.1145528 ,  0.07957879, -0.2799058 , -0.07990456,\n",
       "          0.19642746,  0.24789196, -0.07470398, -0.17983276, -0.28553113,\n",
       "         -0.2519172 ,  0.14935365,  0.11435929, -0.07412092,  0.1906583 ,\n",
       "         -0.13661556,  0.2220375 , -0.11787629, -0.17944914]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_4/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_5/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.22351328,  0.22194001,  0.14984897,  0.11988667, -0.01605284,\n",
       "         -0.23399964,  0.22306421,  0.0278677 ,  0.0426856 , -0.04367705],\n",
       "        [-0.23109737, -0.01278141, -0.09419459, -0.03690362, -0.091415  ,\n",
       "          0.15358299,  0.05917278,  0.277657  , -0.03277618, -0.1370721 ],\n",
       "        [-0.23486102, -0.06312488, -0.24399494, -0.17508598, -0.00511211,\n",
       "          0.02213219, -0.05624901,  0.2717009 ,  0.14521724, -0.01210278],\n",
       "        [-0.0324685 ,  0.20125008,  0.266472  ,  0.0524959 , -0.16962376,\n",
       "         -0.1813922 ,  0.12716803, -0.16471544,  0.14124185, -0.15331756],\n",
       "        [ 0.12261274, -0.27444306,  0.24907961,  0.26261815,  0.12592039,\n",
       "          0.02041641, -0.27426133,  0.27927765, -0.05040485,  0.1282472 ],\n",
       "        [-0.08799557,  0.16287518,  0.13039774,  0.1263552 ,  0.00178006,\n",
       "         -0.00034502, -0.11542153, -0.2844565 ,  0.06427607, -0.25581497],\n",
       "        [ 0.1347653 ,  0.23256704,  0.17898193, -0.09423016, -0.20594135,\n",
       "         -0.18884194, -0.13894631, -0.21465702, -0.17976822, -0.17135194],\n",
       "        [-0.1643705 , -0.17935607, -0.25518733, -0.22788283, -0.1292242 ,\n",
       "         -0.2845924 , -0.12765473, -0.26514435, -0.17383063, -0.17949326],\n",
       "        [ 0.02362308,  0.07465443, -0.21776946, -0.2054641 ,  0.23612121,\n",
       "         -0.08345073, -0.07015058,  0.05232388,  0.203266  ,  0.16055262],\n",
       "        [-0.10704382,  0.16565597,  0.03266457,  0.19539127,  0.01442418,\n",
       "         -0.05871013, -0.24109669, -0.14104633,  0.10746825,  0.2602184 ],\n",
       "        [ 0.02469587, -0.12658188,  0.15494648,  0.05552104,  0.07445556,\n",
       "          0.1368649 ,  0.00854811, -0.04857191,  0.19034392,  0.08810419],\n",
       "        [ 0.19107705,  0.14511839,  0.19144845, -0.07389039,  0.21303847,\n",
       "         -0.0120742 ,  0.06728125,  0.04000852, -0.00322101, -0.18201745],\n",
       "        [-0.0028882 ,  0.2191669 ,  0.28332475,  0.20747423,  0.05407506,\n",
       "          0.2606292 ,  0.22356519, -0.07996124,  0.18885109, -0.25765184],\n",
       "        [ 0.24785104, -0.23916823,  0.24158481,  0.17071345, -0.19999576,\n",
       "         -0.22296059, -0.24427722, -0.28072944,  0.00053748,  0.03947762],\n",
       "        [ 0.277082  ,  0.11609125,  0.22835651,  0.25932798, -0.13820294,\n",
       "          0.2678418 ,  0.14244479,  0.14894775,  0.03325492,  0.16883081],\n",
       "        [ 0.00316873,  0.23596194, -0.2559039 ,  0.16732362,  0.00469059,\n",
       "         -0.08679305, -0.05939235, -0.18803757,  0.11970589,  0.06233093],\n",
       "        [-0.06182957, -0.1511305 ,  0.189879  ,  0.14591703,  0.09312221,\n",
       "          0.09017542,  0.1704613 ,  0.2063753 ,  0.01745191, -0.02743745],\n",
       "        [ 0.19575128, -0.10918055,  0.24548975, -0.15897582, -0.00600722,\n",
       "          0.25170258, -0.06005087,  0.0475055 ,  0.24353305, -0.27517918],\n",
       "        [ 0.0918127 , -0.20440984, -0.1296428 ,  0.21326652, -0.24776089,\n",
       "         -0.12182884, -0.01326632, -0.23957977,  0.06916374, -0.27777866],\n",
       "        [ 0.03904068, -0.08514145,  0.20448118,  0.19308242, -0.25294876,\n",
       "         -0.03505649,  0.14367005, -0.13001049,  0.18796611,  0.18545249],\n",
       "        [ 0.19232038,  0.02595726,  0.16996264, -0.0517386 , -0.08979402,\n",
       "          0.20895454, -0.06157009, -0.02764279,  0.18259498, -0.27810505],\n",
       "        [-0.159644  ,  0.11916161, -0.0950153 , -0.16374978,  0.1338025 ,\n",
       "          0.20142841,  0.13016167,  0.19852018,  0.11872849, -0.21313706],\n",
       "        [-0.26278147,  0.1777164 ,  0.2439669 , -0.28407997,  0.05934346,\n",
       "          0.11266056, -0.11481692,  0.08840194, -0.1009129 ,  0.18880555],\n",
       "        [ 0.08869925, -0.25393295,  0.03716695, -0.22218144,  0.25066814,\n",
       "         -0.18513505, -0.14700434,  0.242358  ,  0.01958159, -0.04020894],\n",
       "        [-0.18143211,  0.14939633,  0.00896353,  0.13055137,  0.08908552,\n",
       "          0.23695311,  0.05282035, -0.2023122 ,  0.05019391,  0.17393717],\n",
       "        [ 0.04573822, -0.17771953,  0.16737846, -0.2789361 , -0.10982272,\n",
       "         -0.17802659, -0.13294649, -0.18270463,  0.05341926, -0.11449729],\n",
       "        [-0.20442024, -0.00672895, -0.13323705,  0.03373238,  0.12718448,\n",
       "         -0.02342987, -0.14074762, -0.26231962, -0.01476356, -0.11833948],\n",
       "        [ 0.06219935, -0.05909139,  0.28255907,  0.12273392,  0.16283986,\n",
       "         -0.10720213, -0.01882359,  0.22157016, -0.01819238, -0.17115445],\n",
       "        [ 0.05109352,  0.07645306,  0.14140344,  0.12419057,  0.23294696,\n",
       "          0.22773579, -0.06242794,  0.04102123, -0.23754962,  0.04134431],\n",
       "        [-0.07144612,  0.10462004,  0.04513857, -0.11297271, -0.19639614,\n",
       "         -0.2638121 ,  0.12960553, -0.04037574,  0.14306244,  0.18871567],\n",
       "        [-0.0688723 , -0.19243115,  0.04618332, -0.2232517 , -0.1816666 ,\n",
       "         -0.25264347,  0.08719456, -0.12101036, -0.03309524, -0.2609359 ],\n",
       "        [-0.04756416,  0.02265105,  0.20801991, -0.13096969,  0.02744985,\n",
       "         -0.13786891, -0.23851073,  0.11635011,  0.2569405 ,  0.1961649 ],\n",
       "        [ 0.01551414,  0.190653  , -0.03656457, -0.13430277, -0.07442883,\n",
       "          0.1359702 , -0.07792036,  0.01034203,  0.20477244,  0.20033514],\n",
       "        [-0.03549233, -0.06135257, -0.10887308,  0.21920905, -0.00138947,\n",
       "          0.02843854,  0.15648565,  0.15395871,  0.18565801, -0.08927447],\n",
       "        [ 0.20524704, -0.21707076, -0.1884678 , -0.02724361, -0.15722877,\n",
       "          0.24188301,  0.12519294, -0.20135191, -0.10513158, -0.2416161 ],\n",
       "        [-0.2478414 , -0.01372242,  0.05235285, -0.04895806,  0.25142798,\n",
       "         -0.25895056, -0.02075866, -0.05119318, -0.09865274,  0.24421331],\n",
       "        [-0.26582915, -0.02414685,  0.26050577,  0.03199401, -0.12648277,\n",
       "         -0.22523278, -0.07402943,  0.26350835, -0.08132826, -0.2846694 ],\n",
       "        [-0.02279505, -0.08198902, -0.2575367 ,  0.0570856 , -0.03584787,\n",
       "         -0.18165621, -0.06986532, -0.01765782, -0.19952692, -0.05722547],\n",
       "        [-0.15372998,  0.1084758 , -0.08754866, -0.08107612,  0.18304616,\n",
       "          0.05023852,  0.07819265, -0.2527538 ,  0.02922013,  0.08189043],\n",
       "        [ 0.2599527 ,  0.15122128, -0.2090601 ,  0.23696926, -0.24807793,\n",
       "         -0.14593849, -0.12692744, -0.13316679,  0.23401788,  0.04202849],\n",
       "        [-0.25736427,  0.27799335, -0.19758427, -0.11203624,  0.21459654,\n",
       "         -0.02434134, -0.08078995,  0.09353757, -0.17916238,  0.17848063],\n",
       "        [-0.1073081 , -0.0649862 , -0.0531953 ,  0.13249719,  0.26227316,\n",
       "          0.11182016, -0.23856741, -0.07957231,  0.13416883,  0.1819615 ],\n",
       "        [-0.09086367, -0.19466417, -0.17969355,  0.09070352, -0.15499672,\n",
       "          0.08952218,  0.28113374, -0.22020721, -0.05650447, -0.03105614],\n",
       "        [-0.27733976,  0.04312918, -0.02555209, -0.17361277, -0.1112023 ,\n",
       "         -0.03325391,  0.23815814, -0.23785953, -0.2212426 ,  0.19189212],\n",
       "        [-0.15227029,  0.23778793, -0.02362865,  0.14818072,  0.03795087,\n",
       "          0.20242083, -0.08855002, -0.09223199,  0.00952879,  0.06630591],\n",
       "        [-0.04467976, -0.08120829,  0.02400115, -0.19746315,  0.19763616,\n",
       "         -0.01325807, -0.06315877, -0.26990685,  0.17269397,  0.26361117],\n",
       "        [ 0.2508087 , -0.03914179, -0.21879166, -0.07806408,  0.1593008 ,\n",
       "          0.02311745, -0.2783619 , -0.08591151,  0.24333337,  0.09436718],\n",
       "        [ 0.10848361, -0.18708028, -0.16206723, -0.23880821, -0.0107452 ,\n",
       "         -0.02094209,  0.05840129, -0.16381815,  0.19735813,  0.1623624 ],\n",
       "        [ 0.26365754, -0.26845342,  0.15715721,  0.02732453, -0.21859765,\n",
       "         -0.02387428,  0.08680114, -0.070462  ,  0.11050922,  0.17023149],\n",
       "        [-0.10935557,  0.02576002, -0.12453869,  0.06142685,  0.27478877,\n",
       "          0.27748308,  0.15721416,  0.24978992, -0.10963915, -0.12250976],\n",
       "        [-0.07689652,  0.2466962 , -0.10083583,  0.02311331,  0.1457389 ,\n",
       "         -0.09861268, -0.2008481 ,  0.15070775,  0.16386852,  0.14840564],\n",
       "        [-0.00654307, -0.09788063, -0.27352953,  0.18471605, -0.23902893,\n",
       "          0.12049529, -0.10017487,  0.16395625,  0.2407848 ,  0.01494673],\n",
       "        [-0.2831748 , -0.11526254, -0.25361142,  0.07685056, -0.18108153,\n",
       "         -0.20360684, -0.06986925,  0.02854192, -0.18009824, -0.2475708 ],\n",
       "        [-0.01522988,  0.02175063, -0.23077096, -0.05341023,  0.06674629,\n",
       "          0.12758699, -0.2361139 , -0.05621745,  0.06256941,  0.01866677],\n",
       "        [-0.20215966,  0.21728739, -0.276402  ,  0.04164484,  0.23488799,\n",
       "          0.22988579,  0.09826955, -0.20095368, -0.27285752, -0.05827761],\n",
       "        [ 0.11729148, -0.15610406, -0.16335455,  0.08232391,  0.16065887,\n",
       "          0.02810824, -0.17853563,  0.08625659, -0.07464546,  0.26487103],\n",
       "        [-0.06305571,  0.05030179,  0.19165361,  0.08673018,  0.10005322,\n",
       "         -0.09145845,  0.1453211 , -0.07164592, -0.07410112, -0.2343111 ],\n",
       "        [-0.21259096,  0.17496121, -0.2631804 ,  0.00048947, -0.07307246,\n",
       "         -0.01548767,  0.18775979, -0.09482799, -0.1439621 , -0.19550225],\n",
       "        [ 0.14600351,  0.16455793,  0.04630461, -0.17899503,  0.16857746,\n",
       "         -0.17758314, -0.02120218,  0.14503026,  0.20783478, -0.04548669],\n",
       "        [-0.09987025,  0.23015168, -0.0272572 ,  0.28193018, -0.03538446,\n",
       "         -0.0050694 , -0.07961738, -0.02690864,  0.15312496,  0.18064141],\n",
       "        [-0.08102737,  0.09419826, -0.15719591,  0.07965738,  0.19051391,\n",
       "          0.24699858, -0.00140402,  0.14202964, -0.2675834 , -0.02993819],\n",
       "        [ 0.17739093,  0.28330293,  0.13154322,  0.12033209,  0.02132919,\n",
       "          0.11929393,  0.20869833,  0.05073297,  0.25914857, -0.16394158],\n",
       "        [-0.11260414,  0.11919501, -0.07746843,  0.20408487,  0.14141774,\n",
       "          0.05409706, -0.23700745,  0.23189822,  0.1250385 , -0.20916793],\n",
       "        [ 0.07233655,  0.07510269, -0.23048787, -0.23304328,  0.11634538,\n",
       "         -0.20798698,  0.12034783,  0.21726784, -0.28273067,  0.06892952]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_5/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `None` in the input shape signals that the batch size could be anything.\n",
    "\n",
    "Now, you can display its contents via the `summary()` method.\n",
    "\n",
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can give names to everything in Keras—every model, every layer.\n",
    "\n",
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can declare the shape of the model’s inputs in advance using `Input` class.\n",
    "\n",
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the `summary`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debug your model incrementally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Functional API\n",
    "\n",
    "The Sequential model has the following characteristics:\n",
    "- Pros: \n",
    "  - easy to use, but \n",
    "- Cons (for practical use):\n",
    "    - its applicability is extremely limited\n",
    "    - it can only express models with a single input and a single output\n",
    "    - applying one layer after the other in a sequential fashion\n",
    "    - models with multiple inputs \n",
    "    - an image and its metadata\n",
    "  - multiple outputs\n",
    "    - different things you want to predict about the data \n",
    "  - a nonlinear topology.\n",
    "\n",
    "Therefore Functional API is used: it feels like playing with **LEGO bricks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A simple example of Functional model\n",
    "\n",
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "\n",
    "- This inputs object \n",
    "  - holds information about the shape and dtype of the data that the model will process.\n",
    "  - Symbolic tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-input, multi-output models\n",
    "- Most deep learning models \n",
    "  - don’t look like lists\n",
    "  - they look like graphs.\n",
    "\n",
    "\n",
    "**Example:**\n",
    "- Create a system to rank customer support tickets \n",
    "  - priority\n",
    "  - route them to the appropriate department\n",
    "- three inputs:\n",
    "  - The title of the ticket (text input)\n",
    "  - The text body of the ticket (text input)\n",
    "  - Any tags added by the user \n",
    "    - categorical input\n",
    "    - one-hot encoded\n",
    "- The text inputs are \n",
    "  - arrays of ones and zeros of size `vocabulary_size`\n",
    "- two outputs:\n",
    "  - The priority score of the ticket\n",
    "    - a scalar between 0 and 1 \n",
    "    - $sigmoid$\n",
    "  - The department that should handle the ticket\n",
    "    - a $softmax$ over the set of departments \n",
    "\n",
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a multi-input, multi-output model\n",
    "\n",
    "Call fit with lists of input and output data:\n",
    "- lists of data: \n",
    "  - in the same order as the inputs you passed to the Model constructor.\n",
    "- dictionary of data:\n",
    "  - don’t want to rely on input order\n",
    "  - uses names of `Input` objects and output layers.\n",
    "  \n",
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The power of the Functional API: Access to layer connectivity\n",
    "\n",
    "A Functional model is an **explicit graph** data structure. \n",
    "-  You can inspect how layers are connected\n",
    "-  reuse previous graph nodes (which are layer outputs) as part of new models.\n",
    "-  It is a \"mental model\" as researchers use:\n",
    "   -  a graph of layers. \n",
    "      -  model visualization (topology of the model)\n",
    "      -  feature extraction \n",
    "\n",
    "**Using `plot_model`  to visualize a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot generated by `plot_model()` on our ticket classifier model](img/07-02.png)\n",
    "\n",
    "**Add shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model plot with shape information added](img/07-03.png)\n",
    "\n",
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature extraction:** Creating models that reuse intermediate features from another model.\n",
    "\n",
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plot of our new model](img/07-04.png)\n",
    "\n",
    "### Subclassing the Model class\n",
    "\n",
    "This is the most advanced method in Keras to create a model.\n",
    "\n",
    "Steps for subclassing:\n",
    "1. Create a subclass of `keras.model`\n",
    "2. In the `__init__()` method, define the layers the model will use.\n",
    "3. In the `call()` method, define the forward pass of the model, reusing the layers previously created.\n",
    "4. Instantiate your subclass, and call it on data to create its weights.\n",
    "\n",
    "**The difference between a Layer subclass and a Model subclass**\n",
    "- a \"layer\" is a building block you use to create models, \n",
    "- a \"model\" is the top-level object that you will actually train, export for inference, etc. \n",
    "- a Model has `fit()`, `evaluate()`, and `predict()` methods. Layers don’t. \n",
    "- you can save a model to a file on disk, but not layers.\n",
    "\n",
    "#### Rewriting our previous example as a subclassed model\n",
    "\n",
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beware: What subclassed models don't support\n",
    "A subclassed model is a piece of bytecode: \n",
    "- a Python class with a `call()` method that contains raw code.\n",
    "- the way layers are connected to each other is hidden inside the body of the call() method\n",
    "  - you cannot access that information\n",
    "  - Calling `summary()` will not display layer connectivity\n",
    "  - you cannot plot the model topology via `plot_model()`. \n",
    "  - you cannot access the nodes of the graph of layers to do feature extraction (no graph).\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixing and matching different components\n",
    "The approaches are all part of the same spectrum of workflows.\n",
    "\n",
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember: Use the right tool for the job\n",
    "Functional API:\n",
    "- good trade-off between ease of use and flexibility.\n",
    "- suitable for models that can be expressed as a directed acyclic graph\n",
    "\n",
    "**Recommendation:**\n",
    "In general, using Functional models that include subclassed layers provides the best of both worlds: \n",
    "- high development flexibility\n",
    "- retaining the advantages of the Functional API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using built-in training and evaluation loops\n",
    "\n",
    "- Progressive disclosure of complexity also applies to model training.\n",
    "- Write a new training algorithm from scratch.\n",
    "  - Provide your own **custom metrics**.\n",
    "  - Pass **callbacks** to the `fit()` method\n",
    "    - schedule actions to be taken at specific points during training.\n",
    "\n",
    "\n",
    "\n",
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own metrics\n",
    "A Keras metric is a subclass of the `keras.metrics.Metric` class. \n",
    "- a metric has an internal state stored in TensorFlow variables. \n",
    "- these variables aren’t updated via backpropagation\n",
    "  - you have to write the `state-update` logic yourself in the `update_state()` method.\n",
    "- You use the `result()` method to return the current value of the metric\n",
    "- use `reset_state()` method to reset the metric state without having to reinstantiate it\n",
    "  - this enables the same metric objects to be used across different epochs of training\n",
    "  - across both training and evaluation.\n",
    "\n",
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using callbacks\n",
    "- Do not use a paper plane, but a drone that can sense its environment!\n",
    "- The Keras **callbacks API** makes your `model.fit()` more smarter.\n",
    "\n",
    "**What is a callback:**\n",
    "- an object (a class instance implementing specific methods) that is passed to the model in the call to `fit()` \n",
    "  - is called by the model at various points during training. \n",
    "  - It has access to all the available data about the state of the model and its performance\n",
    "- it can take action: \n",
    "  - interrupt training, \n",
    "  - save a model, \n",
    "  - load a different weight set, \n",
    "  - alter the state of the model.\n",
    "\n",
    "**Some built-in callbacks in Keras:**\n",
    "- keras.callbacks.ModelCheckpoint\n",
    "- keras.callbacks.EarlyStopping \n",
    "- keras.callbacks.LearningRateScheduler \n",
    "- keras.callbacks.ReduceLROnPlateau \n",
    "- keras.callbacks.CSVLogger\n",
    "\n",
    "**Descriptions:**\n",
    "- _Model checkpointing_\n",
    "  - Saving the current state of the model at different points during training.\n",
    "- _Early stopping_:\n",
    "    - Interrupting training when the validation loss is no longer improving\n",
    "    - saving the best model obtained during training\n",
    "- _Dynamically adjusting_:\n",
    "  - Adjusting the value of certain parameters during training\n",
    "    - Such as the learning rate of the optimizer.\n",
    "- _Logging_:\n",
    "  - to log training and validation metrics during training, \n",
    "  - visualizing the representations learned by the model as they’re updated\n",
    "  - The fit() progress bar that you’re familiar with is in fact a callback!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks\n",
    "\n",
    "- `EarlyStopping` callback:\n",
    "  - Running a training loop from scratch after finding the optimal number of epochs to minimize the validation accuracy is a wasteful approach.\n",
    "  - A much better way to handle this is to stop training when you measure that the validation loss is no longer improving.\n",
    "    - interrupt training as soon as you start overfitting, thus avoiding having to retrain your model for a smaller number of epochs.\n",
    "- `ModelCheckpoint` callback:\n",
    "  - lets you continually save the (best) model during training.\n",
    "\n",
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own callbacks\n",
    "\n",
    "- Callbacks are implemented by subclassing the `keras.callbacks.Callback` class. \n",
    "- You can then implement any number of the following transparently named methods, which are called at various points during training:\n",
    "  - `on_epoch_begin(epoch, logs)`\n",
    "  - `on_epoch_end(epoch, logs)`\n",
    "  - `on_batch_begin(batch, logs)`\n",
    "  - `on_batch_end(batch, logs)`\n",
    "  - `on_train_begin(logs)`\n",
    "  - `on_train_end(logs)`\n",
    "- `logs` argument is a dictionary containing information about the previous batch, epoch, or training run—training and validation metrics, and so on. \n",
    "- The `on_epoch_*` and `on_batch_*` methods also take the epoch or batch index as their first argument (an integer).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring and visualization with TensorBoard\n",
    "\n",
    "Keras helps you go from idea to experiment in the least possible time, and fast GPUs can help you get from experiment to result as quickly as possible. \n",
    "\n",
    "![The loop of progress](img/07-06.png)\n",
    "\n",
    "\n",
    "- TensorBoard is a browser-based application that you can run locally.\n",
    "  - `pip install tensorboard` \n",
    "  - `tensorboard --logdir /full_path_to_your_log_dir`\n",
    "- It’s the best way to monitor everything that goes on inside your model during training:\n",
    "  - Visually monitor metrics during training\n",
    "  - Visualize your model architecture\n",
    "  - Visualize histograms of activations and gradients\n",
    "  - Explore embeddings in 3D\n",
    "- The easiest way to use TensorBoard with a Keras model and the `fit()` method is to use the `keras.callbacks.TensorBoard` callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Colab Notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TensorBoard can be used for easy monitoring of training and evaluation metrics.](img/07-07.png)\n",
    "\n",
    "## Writing your own training and evaluation loops\n",
    "\n",
    "The `fit()` method:\n",
    "- strikes a nice balance between \n",
    "  - ease of use \n",
    "  - flexibility. \n",
    "- It’s what you will use most of the time. \n",
    "- But may be limited for a deep learning researcher for some applications:\n",
    "  - generative learning (which we will discuss in chapter 12), \n",
    "  - self-supervised learning (where targets are obtained from the inputs), \n",
    "  - reinforcement learning (where learning is driven by occasional “rewards,” much like training a dog)\n",
    "\n",
    "**Steps of a typical training loop:**\n",
    "1. Run the forward pass\n",
    "  - compute the model’s output inside a gradient tape to obtain a loss value for the current batch of data.\n",
    "2. Retrieve the gradients of the loss with regard to the model’s weights.\n",
    "3. Update the model’s weights so as to lower the loss value on the current batch of data.\n",
    "4. These steps are repeated for as many batches as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training versus inference\n",
    "- Some Keras layers, such as the `Dropout` layer, have different behaviors during training and inference.\n",
    "- Calling `dropout(inputs, training=True)` will drop some activation entries,\n",
    "- Calling `dropout(inputs, training=False)` does nothing. \n",
    "\n",
    "- Two kinds of weights of layers and models:\n",
    "  1. Trainable weights\n",
    "     * These are meant to be updated via backpropagation to minimize the loss of the model\n",
    "     * the kernel and bias of a Dense layer.\n",
    "  2. Non-trainable weights\n",
    "     * These are meant to be updated during the forward pass by the layers that own them. \n",
    "     * For instance, if you wanted a custom layer to keep a counter of how many batches it has processed so far, that information would be stored in a non-trainable weight, and at each batch, your layer would increment the counter by one.\n",
    "     * `BatchNormalization` layer\n",
    "\n",
    "- Don't use `tape.gradients(loss, model.weights)`, but rather `tape.gradients(loss, model.trainable_weights)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# NOTE: This is a sample snippet only! Don't run it. \n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradients(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-level usage of metrics\n",
    "\n",
    "In a low-level training loop, you will probably want to leverage Keras metrics\n",
    "- custom\n",
    "- built-in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also need to track the average of a scalar value, such as the model’s loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A complete training and evaluation loop\n",
    "Let’s combine all steps:\n",
    "- forward pass, \n",
    "- backward pass, \n",
    "- metrics tracking into a `fit()`\n",
    "- displaying the logs by the `fit()` progress bar.\n",
    "\n",
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to reset the state of our metrics at the start of each epoch and before running evaluation.\n",
    "\n",
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use a `tf.data.Dataset` object to turn our NumPy data into an iterator that iterates over the data in batches of size 32.\n",
    "\n",
    "\n",
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation:**\n",
    "Evaluation step omits the code that deals with updating the weights of the model\n",
    "- GradientTape \n",
    "- Optimizer\n",
    "\n",
    "\n",
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make it fast with tf.function\n",
    "Your code is correct but slow:\n",
    "- By default, TensorFlow code is executed \n",
    "  - line by line, \n",
    "  - eagerly, \n",
    "  - much like NumPy code or regular Python code. \n",
    "  - easier to debug your code, \n",
    "  - far from optimal from a performance standpoint.\n",
    "- Compile your TensorFlow code \n",
    "  - converts it into a **computation graph**\n",
    "  - can be globally optimized\n",
    "  - just add a `@tf.function` to any function you want to compile before executing\n",
    "\n",
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging fit() with a custom training loop\n",
    "Using a training loop written from scratch:\n",
    "-  the most flexibility\n",
    "-  writing a lot of code \n",
    "-  missing out on many convenient features of fit()\n",
    "   -  such as callbacks\n",
    "   -  built-in support for distributed training.\n",
    "\n",
    "You can provide a custom training step function and let the framework do the rest:\n",
    "- override the `train_step()` method of the `Model` class.\n",
    "- This is the function that is called by `fit()` for every batch of data.\n",
    "- You don’t need to use a `@tf.function` decorator when you override `train_step` — the framework does it for you.\n",
    "\n",
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate our custom model, compile it (we only pass the optimizer, since the loss is already defined outside of the model), and train it using `fit()` as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can thus write the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Keras offers a spectrum of different workflows, based on the principle of progressive disclosure of complexity. They all smoothly inter-operate together.\n",
    "- You can build models via the Sequential class, via the Functional API, or by subclassing the Model class. Most of the time, you’ll be using the Functional API.\n",
    "- The simplest way to train and evaluate a model is via the default `fit()` and `evaluate()` methods.\n",
    "- Keras callbacks provide a simple way to monitor models during your call to `fit()` and automatically take action based on the state of the model.\n",
    "- You can also fully take control of what `fit()` does by overriding the `train_step()` method.\n",
    "- Beyond `fit()`, you can also write your own training loops entirely from scratch. \n",
    "  - This is useful for researchers implementing brand-new training algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
