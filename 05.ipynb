{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "text"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        @font-face {\n",
       "            /* تعریف نام فونت */\n",
       "            font-family: 'BZar';\n",
       "            /* اکسپلورر 9 به بعد */\n",
       "            src: url('font/BZar.eot');\n",
       "            /* بررسی نصب بودن فونت در سیستم کاربر */\n",
       "            src: local('bZar'),\n",
       "                 /* برای برخی از مرورگرها مانند سافاری */\n",
       "                 local('b Zar'),\n",
       "                 /* هک برای اکسپلورر 8 و ماقبل */\n",
       "                 url('font/BZar.eot?#iefix') format('embedded-opentype'),\n",
       "                 /* فرمت مناسب مرورگرهای خیلی جدید */\n",
       "                 url('font/BZar.woff2') format('woff2'),\n",
       "                 /* فرمت مناسب مرورگرهای تقریبا جدید */\n",
       "                 url('font/BZar.woff') format('woff'),\n",
       "                 /* تمام مرورگرها به جزء اکسپلورر */\n",
       "                 url('font/BZar.ttf') format('truetype'),\n",
       "                 /* نسخه‌های قدیمی سیستم عامل iOS */\n",
       "                 url('font/BZar.svg#BZar') format('svg');\n",
       "            font-style: normal;\n",
       "            font-weight: normal;\n",
       "            font-display: swap;\n",
       "        }\n",
       "    \n",
       "    \n",
       "        .reveal .slides {\n",
       "            direction: rtl;\n",
       "            text-align: right;\n",
       "        }\n",
       "        \n",
       "        div {\n",
       "            direction: ltr;\n",
       "            text-align: left;\n",
       "        }\n",
       "        \n",
       "        p > img {\n",
       "          display: block;\n",
       "          margin-left: auto;\n",
       "          margin-right: auto;\n",
       "          max-width:75%; \n",
       "          height:auto;\n",
       "        }\n",
       "        \n",
       "        div.text_cell_render.rendered_html > *, li > p, .rendered_html p, #quarto-document-content > *\n",
       "        {\n",
       "            direction: rtl;\n",
       "            text-align: right;\n",
       "            font-family: BZar, Tahoma, Geneva, sans-serif;\n",
       "            font-size: x-large;\n",
       "            line-height: 26pt;\n",
       "            color: black;\n",
       "        }\n",
       "        \n",
       "        .jp-CodeMirrorEditor .jp-Editor .jp-InputArea-editor {\n",
       "            direction: rtl !important;\n",
       "        }\n",
       "        \n",
       "        .CodeMirror-lines .output_subarea .output_text .output_stream .output_stdout{\n",
       "            direction: ltr !important;\n",
       "        }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "def f():\n",
    "    return HTML(\"\"\"\n",
    "    <style>\n",
    "        @font-face {\n",
    "            /* تعریف نام فونت */\n",
    "            font-family: 'BZar';\n",
    "            /* اکسپلورر 9 به بعد */\n",
    "            src: url('font/BZar.eot');\n",
    "            /* بررسی نصب بودن فونت در سیستم کاربر */\n",
    "            src: local('bZar'),\n",
    "                 /* برای برخی از مرورگرها مانند سافاری */\n",
    "                 local('b Zar'),\n",
    "                 /* هک برای اکسپلورر 8 و ماقبل */\n",
    "                 url('font/BZar.eot?#iefix') format('embedded-opentype'),\n",
    "                 /* فرمت مناسب مرورگرهای خیلی جدید */\n",
    "                 url('font/BZar.woff2') format('woff2'),\n",
    "                 /* فرمت مناسب مرورگرهای تقریبا جدید */\n",
    "                 url('font/BZar.woff') format('woff'),\n",
    "                 /* تمام مرورگرها به جزء اکسپلورر */\n",
    "                 url('font/BZar.ttf') format('truetype'),\n",
    "                 /* نسخه‌های قدیمی سیستم عامل iOS */\n",
    "                 url('font/BZar.svg#BZar') format('svg');\n",
    "            font-style: normal;\n",
    "            font-weight: normal;\n",
    "            font-display: swap;\n",
    "        }\n",
    "    \n",
    "    \n",
    "        .reveal .slides {\n",
    "            direction: rtl;\n",
    "            text-align: right;\n",
    "        }\n",
    "        \n",
    "        div {\n",
    "            direction: ltr;\n",
    "            text-align: left;\n",
    "        }\n",
    "        \n",
    "        p > img {\n",
    "          display: block;\n",
    "          margin-left: auto;\n",
    "          margin-right: auto;\n",
    "          max-width:75%; \n",
    "          height:auto;\n",
    "        }\n",
    "        \n",
    "        div.text_cell_render.rendered_html > *, li > p, .rendered_html p, #quarto-document-content > *\n",
    "        {\n",
    "            direction: rtl;\n",
    "            text-align: right;\n",
    "            font-family: BZar, Tahoma, Geneva, sans-serif;\n",
    "            font-size: x-large;\n",
    "            line-height: 26pt;\n",
    "            color: black;\n",
    "        }\n",
    "        \n",
    "        .jp-CodeMirrorEditor .jp-Editor .jp-InputArea-editor {\n",
    "            direction: rtl !important;\n",
    "        }\n",
    "        \n",
    "        .CodeMirror-lines .output_subarea .output_text .output_stream .output_stdout{\n",
    "            direction: ltr !important;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\")\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <link rel=\"stylesheet\" href=\"css/jquery.jqZoom.css\" />\n",
       "    <script src=\"js/jquery-1.12.4.min.js\"></script>\n",
       "    <script src=\"js/jquery.zoom.min.js\"></script>\n",
       "    <script>\n",
       "        $(document).ready(function(){\n",
       "            $(\"img\").children().off();\n",
       "            $('img')\n",
       "            .wrap('<span style=\"display:inline-block\"></span>')\n",
       "            .css('display', 'block')\n",
       "            .parent()\n",
       "            .zoom({ on:'grab', duration: 150, magnify: 1 });\n",
       "        });\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Javascript\n",
    "\n",
    "def g():\n",
    "    return HTML(\"\"\"\n",
    "    <link rel=\"stylesheet\" href=\"css/jquery.jqZoom.css\" />\n",
    "    <script src=\"js/jquery-1.12.4.min.js\"></script>\n",
    "    <script src=\"js/jquery.zoom.min.js\"></script>\n",
    "    <script>\n",
    "        $(document).ready(function(){\n",
    "            $(\"img\").children().off();\n",
    "            $('img')\n",
    "            .wrap('<span style=\"display:inline-block\"></span>')\n",
    "            .css('display', 'block')\n",
    "            .parent()\n",
    "            .zoom({ on:'grab', duration: 150, magnify: 1 });\n",
    "        });\n",
    "    </script>\n",
    "    \"\"\")\n",
    "\n",
    "g()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"فصل پنجم\"\n",
    "format: \n",
    "  docx:\n",
    "    toc: true\n",
    "    section-numbers: true\n",
    "    highlight-style: github\n",
    "    dir: rtl\n",
    "#  pptx:\n",
    "#    toc: true\n",
    "#    execute:\n",
    "#      echo: false\n",
    "#      warning: false\n",
    "  html:\n",
    "    css: css/style.css \n",
    "    code-fold: false \n",
    "    echo: true \n",
    "    self-contained: false \n",
    "    lang: fa\n",
    "#  revealjs: \n",
    "#    incremental: true\n",
    "#    dir: rtl \n",
    "#  pdf:\n",
    "#    number-sections: true\n",
    "#    colorlinks: true\n",
    "#    pdf-engine: xelatex\n",
    "#    keep-tex: true\n",
    "page-layout: full\n",
    "toc: false \n",
    "dir: rtl  \n",
    "lang: fa  \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### این فصل موارد زیر را پوشش می‌دهد:\n",
    "\n",
    "* درک مصالحه بین تعمیم و بهینه‌سازی که مسئله اساسی در یادگیری ماشین است. \n",
    "* روش‌های ارزیابی برای مدل‌های یادگیری ماشین\n",
    "* بهترین شیوه‌ها برای بهبود برازش مدل\n",
    "* بهترین شیوه‌ها برای دستیابی به تعمیم بهتر و مقابله با بیش‌برازش به عنوان مشکل اصلی در یادگیری ماشین"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تعمیم: هدف یادگیری ماشینی\n",
    "\n",
    "- در سه مثال ارائه شده در فصل 4 یعنی پیش‌بینی بررسی فیلم، طبقه‌بندی موضوع، و رگرسیون قیمت مسکن - داده‌ها را به یک مجموعه آموزشی، یک مجموعه اعتبارسنجی و یک مجموعه آزمایشی تقسیم کردیم.\n",
    "- دلیل ارزیابی نکردن مدل‌ها بر اساس داده‌های آموزشی همان مشکل بیش‌برازش `overfitting` بود یعنی پس از چند دوره، عملکرد مدل بر روی داده‌های اعتبارسنجی که قبلاً دیده نشده بود، از عملکرد روی داده‌های آموزشی بسیار بدتر می‌شد در حالی که با دقت آموزش بهبود می‌یافت.\n",
    "    - مدل‌ها شروع به بیش‌برازش کردند.\n",
    "    - بیش‌برازش در هر مشکل یادگیری ماشینی اتفاق می‌افتد.\n",
    "\n",
    "- مسئله اساسی در یادگیری ماشین مصالحه بین بهینه‌سازی (optimization) و تعمیم (generalization) است.\n",
    "    - _بهینه‌سازی_ به فرآیند تنظیم یک مدل برای دستیابی به بهترین عملکرد ممکن در داده‌های آموزشی اشاره دارد (_یادگیری_ در _یادگیری ماشینی_)، \n",
    "    _تعمیم_به عملکرد مدل آموزش دیده بر روی داده‌هایی اشاره دارد که قبلاً هرگز ندیده است.\n",
    "- در حالی که داده‌های اعتبارسنجی قبلا دیده نشده‌اند چطور می‌توانیم دقت مدل را روی آنها افزایش دهیم؟\n",
    "    - جواب: تعمیم\n",
    "\n",
    "- اگر بیش از حد روی بهینه‌سازی کار کنیم دچار بیش‌برازش می‌شویم و تعمیم آسیب می‌بیند."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and overfitting\n",
    "\n",
    "- الگوی شکل زیر در روش های ML عمومیت دارد و آن را با هر نوع مدل و هر مجموعه داده‌ای خواهید دید.\n",
    "\n",
    "![Canonical overfitting behavior](img/05-01.png)\n",
    "\n",
    "در ابتدای آموزش، بهینه‌سازی و تعمیم همبستگی دارند: هرچه تلفات داده‌های آموزشی کمتر باشد، خطای داده‌های آزمون هم کمتر می‌شود.\n",
    "- در حالی که این اتفاق می‌افتد، گفته می‌شود مدل شما _underfit_ است: \n",
    "\n",
    "- هنوز جای پیشرفت وجود دارد. \n",
    "\n",
    "- شبکه هنوز تمام الگوهای مرتبط در داده‌های آموزشی را مدل‌سازی نکرده است.\n",
    "- اما پس از تعداد معینی تکرار در داده‌های آموزشی، تعمیم‌ بهبود نمی‌یابد، بهبود معیارهای اعتبارسنجی متوقف می‌شوند و سپس شروع به تنزل می‌کنند: \n",
    "- مدل شروع به بیش‌برازش برازش می‌کند.\n",
    "- یعنی شروع به یادگیری الگوهایی می‌کند که مختص داده‌های آموزشی هستند، \n",
    "- اما وقتی داده‌های جدید از راه می‌رسند، مدل گمراه می‌شود.\n",
    "\n",
    "احتمال رخداد بیش‌برازش در موارد زیر بیشتر هست:\n",
    "- داده‌ها نویزی باشد، \n",
    "- شامل عدم قطعیت باشد، \n",
    "- شامل ویژگی‌های کمیاب باشد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy training data\n",
    "\n",
    "در مجموعه داده‌های دنیای واقعی، نامعتبر بودن برخی ورودی‌ها نسبتاً رایج است.\n",
    "- برای مثال، شاید یک رقم MNIST می‌تواند یک تصویر تمام سیاه یا چیزی شبیه شکل زیر باشد.\n",
    "\n",
    "![Some pretty weird MNIST training samples](img/05-02.png)\n",
    "\n",
    "این‌ها چه ارقامی هستند؟! \n",
    "\n",
    "- اما همه آنها بخشی از مجموعه آموزشی MNIST هستند.\n",
    "\n",
    "- اتفاق بد زمانی رخ می‌دهد که این داده‌ها به اشتباه برچسب‌گذاری می‌شوند.\n",
    "\n",
    "![Mislabeled MNIST training samples](img/05-03.png)\n",
    "\n",
    "اگر مجموعه داده دارای چنین داده‌های پرتی باشد، عملکرد تعمیم آن کاهش می‌یابد، \n",
    "     \n",
    "- به عنوان مثال، 4 که به نظر می‌رسد بسیار نزدیک به 4 in برچسب اشتباه است\n",
    "  \n",
    "![may end up getting classified as a 9.](img/05-03.png)\n",
    "\n",
    "![Dealing with outliers: robust fit vs. overfitting](img/05-04.png)\n",
    "\n",
    "## ویژگی‌های مبهم\n",
    "- گاهی داده‌ها شامل عدم قطعیت و ابهام هستند:\n",
    "    - آیا کیفیت میوه مناسب هست؟\n",
    "    - آیا هوا خوب هست؟\n",
    "- یک مدل خوب باید در کنار پیش‌بینی به داده‌ها در به مناطق مبهم فضای ویژگی، مانند شکل 5.5، احتمال (قطعیت) اضافه کند.\n",
    "\n",
    "![Robust fit vs. overfitting giving an ambiguous area of the feature space](img/05-05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ویژگی‌های نادر و همبستگی‌های جعلی\n",
    "\n",
    "- اگر برخی نمونه‌ها یا مقادیر ویژگی‌ها کم باشند ممکن است استنتاج نادرستی در مدل صورت بگیرد. \n",
    "- مدل‌های یادگیری ماشینی آموزش‌دیده بر روی مجموعه داده‌هایی که شامل مقادیر ویژگی‌های کمیاب هستند، بسیار مستعد برازش بیش‌برازش هستند.\n",
    "- در یک کار طبقه‌بندی احساسات (`sentiment analysis`)، اگر یک کلمه کمیاب فقط در یک متن در داده‌های آموزشی ظاهر شود، و این متن از نظر احساسات منفی باشد، یک مدل ضعیف ممکن است وجود این کلمه را متناسب با طبقه منفی طبقه‌بندی کند، در حالی که در واقع چنین چیزی نیست!\n",
    "\n",
    "- وجود داده‌های نویزی از داده‌های با مقدار ثابت و بی‌معنا هم بیشتر هست، زیرا ممکن هست یک همبستگی نادرست با برچسب‌ها توسط مدل استنتاج شود. \n",
    "- این یکی از رایج ترین منابع بیش برازش است.\n",
    "\n",
    "### مثال: \n",
    "مجموعه داده MNIST را در نظر بگیرید. به دو روش زیر هر بار اندازه مجموعه داده را دو برابر کنید.\n",
    "    - با الحاق 784 بعد نویز سفید به 784 بعد موجود داده \n",
    "    - با الحاق 784 بعد داده تمام صفر به 784 بعد موجود داده \n",
    "- این الحاق ویژگی‌های بی معنی بر محتوای اطلاعاتی داده‌ها تأثیر نمی‌گذارد:\n",
    "    - دقت طبقه‌بندی انسان به هیچ وجه تحت تأثیر این دگرگونی‌ها قرار نمی‌گیرد.\n",
    "\n",
    "**افزودن کانال‌های نویز سفید یا کانال‌های تمام صفر به MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**آموزش همان مدل بر روی داده‌های MNIST با کانال‌های نویز یا کانال‌های صفر***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:07:12.077442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-06 15:07:12.079098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.079689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080209: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080703: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080788: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080898: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib64/::/lib/:/envs/both/lib/\n",
      "2023-05-06 15:07:12.080959: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-06 15:07:12.081652: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 12s 31ms/step - loss: 0.6187 - accuracy: 0.8141 - val_loss: 0.3314 - val_accuracy: 0.8978\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2524 - accuracy: 0.9222 - val_loss: 0.2761 - val_accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1636 - accuracy: 0.9495 - val_loss: 0.1645 - val_accuracy: 0.9512\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.1175 - accuracy: 0.9636 - val_loss: 0.1535 - val_accuracy: 0.9527\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0851 - accuracy: 0.9734 - val_loss: 0.1316 - val_accuracy: 0.9613\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.0643 - accuracy: 0.9794 - val_loss: 0.1313 - val_accuracy: 0.9617\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.1127 - val_accuracy: 0.9701\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.1385 - val_accuracy: 0.9646\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.1509 - val_accuracy: 0.9648\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1316 - val_accuracy: 0.9687\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2876 - accuracy: 0.9160 - val_loss: 0.1446 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1189 - accuracy: 0.9651 - val_loss: 0.1006 - val_accuracy: 0.9708\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0785 - accuracy: 0.9764 - val_loss: 0.0965 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0565 - accuracy: 0.9833 - val_loss: 0.0901 - val_accuracy: 0.9743\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0427 - accuracy: 0.9874 - val_loss: 0.0805 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.0894 - val_accuracy: 0.9762\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0241 - accuracy: 0.9933 - val_loss: 0.0848 - val_accuracy: 0.9768\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 10s 28ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0810 - val_accuracy: 0.9797\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 11s 28ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0832 - val_accuracy: 0.9806\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 11s 30ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.0868 - val_accuracy: 0.9787\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ترسیم مقایسه دقت اعتبارسنجی**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe13047dfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "علی‌رغم وجود داده‌هایی که در هر دو مورد اطلاعات یکسانی دارند، صرفاً به واسطه‌ی تأثیر همبستگی‌های جعلی، دقت اعتبار مدل آموزش‌دیده شده با وجود کانال‌های نویز تقریباً یک درصد کمتر می‌شود (شکل 5.6 را ببینید) - \n",
    "    - به طور کلی هرچه کانال‌های نویز بیشتری اضافه کنید، دقت بیشتر کاهش می‌یابد.\n",
    "\n",
    "![Effect of noise channels on validation accuracy](img/05-06.png)\n",
    "\n",
    "- ویژگی‌های نویزی به طور اجتناب‌ناپذیری منجر به بیش‌برازش می‌شود.\n",
    "- به این ترتیب، در مواردی که مطمئن نیستید ویژگی‌هایی که دارید شامل اطلاعات مفیدی هستند یا پرت هستند، معمولاً قبل از آموزش _انتخاب ویژگی_ را انجام دهید.\n",
    "- به عنوان مثال، محدود کردن داده‌های IMDB به 10000 کلمه متداول برتر، شکل اولیه‌ای از انتخاب ویژگی بود.\n",
    "- روش معمولی برای انجام انتخاب ویژگی این است که برای هر ویژگی موجود مقداری امتیاز سودمندی را محاسبه کنید \n",
    "    - معیار میزان آموزنده بودن ویژگی با توجه به کاربرد تعیین می‌شود:\n",
    "        - حفظ ویژگی‌هایی که (واریانس آنها) از یک مقدار آستانه بیشتر هست.\n",
    "        - بر اساس ارتباط اطلاعاتی متقابل بین ویژگی و برچسب‌ها \n",
    "    - انجام این کار کانال‌های نویز سفید را در مثال قبل فیلتر می‌کند.\n",
    "\n",
    "### ماهیت تعمیم در یادگیری عمیق\n",
    "\n",
    "در مورد مدل‌های یادگیری عمیق می‌توان آن‌ها را برای تناسب با هر چیزی (!) آنقدر آموزش داد، تا زمانی که قدرت بازنمایی (`representational power`) کافی داشته باشند!\n",
    "     - سعی کنید برچسب‌های MNIST را به هم بزنید و یک مدل در آن آموزش دهید. خطا کاهش می‌يابد!\n",
    "     - اما خطای اعتبارسنجی شاهد هیچ بهبودی نخواهد بود.\n",
    "\n",
    "** تطبیق یک مدل MNIST با برچسب‌های به هم ریخته تصادفی **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 2.3170 - accuracy: 0.1049 - val_loss: 2.3097 - val_accuracy: 0.1009\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2999 - accuracy: 0.1171 - val_loss: 2.3178 - val_accuracy: 0.1023\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2897 - accuracy: 0.1287 - val_loss: 2.3226 - val_accuracy: 0.0999\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2760 - accuracy: 0.1406 - val_loss: 2.3283 - val_accuracy: 0.1019\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 2.2581 - accuracy: 0.1571 - val_loss: 2.3421 - val_accuracy: 0.1010\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2384 - accuracy: 0.1690 - val_loss: 2.3567 - val_accuracy: 0.1020\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.2120 - accuracy: 0.1840 - val_loss: 2.3759 - val_accuracy: 0.0971\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.1845 - accuracy: 0.1998 - val_loss: 2.3940 - val_accuracy: 0.0990\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.1557 - accuracy: 0.2167 - val_loss: 2.4124 - val_accuracy: 0.0967\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.1234 - accuracy: 0.2323 - val_loss: 2.4445 - val_accuracy: 0.1002\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 2.0919 - accuracy: 0.2477 - val_loss: 2.4679 - val_accuracy: 0.0996\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 2.0579 - accuracy: 0.2615 - val_loss: 2.4885 - val_accuracy: 0.0993\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 2.0235 - accuracy: 0.2765 - val_loss: 2.5107 - val_accuracy: 0.0972\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9873 - accuracy: 0.2939 - val_loss: 2.5551 - val_accuracy: 0.0970\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9548 - accuracy: 0.3093 - val_loss: 2.5892 - val_accuracy: 0.0992\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.9191 - accuracy: 0.3219 - val_loss: 2.6035 - val_accuracy: 0.0975\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.8822 - accuracy: 0.3371 - val_loss: 2.6488 - val_accuracy: 0.0989\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.8510 - accuracy: 0.3519 - val_loss: 2.6884 - val_accuracy: 0.0991\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.8167 - accuracy: 0.3665 - val_loss: 2.7153 - val_accuracy: 0.0992\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.7834 - accuracy: 0.3803 - val_loss: 2.7531 - val_accuracy: 0.1016\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.7519 - accuracy: 0.3902 - val_loss: 2.8068 - val_accuracy: 0.1004\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.7218 - accuracy: 0.4011 - val_loss: 2.8274 - val_accuracy: 0.0976\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.6898 - accuracy: 0.4121 - val_loss: 2.8591 - val_accuracy: 0.0972\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.6598 - accuracy: 0.4250 - val_loss: 2.9152 - val_accuracy: 0.0968\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.6317 - accuracy: 0.4367 - val_loss: 2.9632 - val_accuracy: 0.0988\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.6010 - accuracy: 0.4464 - val_loss: 2.9874 - val_accuracy: 0.0975\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5732 - accuracy: 0.4597 - val_loss: 3.0367 - val_accuracy: 0.0958\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.5463 - accuracy: 0.4690 - val_loss: 3.0663 - val_accuracy: 0.1016\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.5177 - accuracy: 0.4778 - val_loss: 3.1340 - val_accuracy: 0.1011\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4923 - accuracy: 0.4872 - val_loss: 3.1668 - val_accuracy: 0.0968\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.4651 - accuracy: 0.4995 - val_loss: 3.2274 - val_accuracy: 0.0978\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.4407 - accuracy: 0.5074 - val_loss: 3.2600 - val_accuracy: 0.1009\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.4141 - accuracy: 0.5179 - val_loss: 3.3207 - val_accuracy: 0.1003\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3910 - accuracy: 0.5267 - val_loss: 3.3723 - val_accuracy: 0.1021\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3673 - accuracy: 0.5350 - val_loss: 3.4244 - val_accuracy: 0.0949\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.3426 - accuracy: 0.5416 - val_loss: 3.4648 - val_accuracy: 0.1008\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.3219 - accuracy: 0.5510 - val_loss: 3.5090 - val_accuracy: 0.1002\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.2989 - accuracy: 0.5587 - val_loss: 3.5901 - val_accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.2770 - accuracy: 0.5653 - val_loss: 3.6076 - val_accuracy: 0.0994\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.2563 - accuracy: 0.5734 - val_loss: 3.6826 - val_accuracy: 0.0977\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 1.2346 - accuracy: 0.5821 - val_loss: 3.7369 - val_accuracy: 0.1001\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.2149 - accuracy: 0.5908 - val_loss: 3.7842 - val_accuracy: 0.0978\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 1.1948 - accuracy: 0.5950 - val_loss: 3.8055 - val_accuracy: 0.1009\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.1755 - accuracy: 0.6025 - val_loss: 3.8898 - val_accuracy: 0.1014\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1561 - accuracy: 0.6122 - val_loss: 3.9250 - val_accuracy: 0.0997\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1385 - accuracy: 0.6170 - val_loss: 3.9855 - val_accuracy: 0.0997\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1210 - accuracy: 0.6211 - val_loss: 4.0296 - val_accuracy: 0.1002\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.1020 - accuracy: 0.6292 - val_loss: 4.0884 - val_accuracy: 0.0970\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.0845 - accuracy: 0.6344 - val_loss: 4.1604 - val_accuracy: 0.0980\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0683 - accuracy: 0.6437 - val_loss: 4.1984 - val_accuracy: 0.1013\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0501 - accuracy: 0.6483 - val_loss: 4.2637 - val_accuracy: 0.0990\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.0329 - accuracy: 0.6531 - val_loss: 4.3312 - val_accuracy: 0.0983\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0164 - accuracy: 0.6581 - val_loss: 4.3996 - val_accuracy: 0.0977\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 1.0010 - accuracy: 0.6662 - val_loss: 4.4368 - val_accuracy: 0.0987\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.9852 - accuracy: 0.6695 - val_loss: 4.4946 - val_accuracy: 0.0997\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.9703 - accuracy: 0.6780 - val_loss: 4.5427 - val_accuracy: 0.0979\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.9528 - accuracy: 0.6818 - val_loss: 4.6327 - val_accuracy: 0.0989\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.9404 - accuracy: 0.6878 - val_loss: 4.6456 - val_accuracy: 0.0996\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.9238 - accuracy: 0.6940 - val_loss: 4.7440 - val_accuracy: 0.0969\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.9101 - accuracy: 0.6969 - val_loss: 4.7981 - val_accuracy: 0.1010\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.8986 - accuracy: 0.7015 - val_loss: 4.8315 - val_accuracy: 0.0972\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8813 - accuracy: 0.7096 - val_loss: 4.9173 - val_accuracy: 0.0976\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.8683 - accuracy: 0.7134 - val_loss: 4.9923 - val_accuracy: 0.0987\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.8554 - accuracy: 0.7170 - val_loss: 5.0549 - val_accuracy: 0.0970\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 7s 20ms/step - loss: 0.8419 - accuracy: 0.7204 - val_loss: 5.1233 - val_accuracy: 0.0967\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8291 - accuracy: 0.7252 - val_loss: 5.1748 - val_accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.8186 - accuracy: 0.7284 - val_loss: 5.2372 - val_accuracy: 0.0986\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.8050 - accuracy: 0.7333 - val_loss: 5.2976 - val_accuracy: 0.0974\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.7926 - accuracy: 0.7387 - val_loss: 5.3675 - val_accuracy: 0.0968\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7784 - accuracy: 0.7445 - val_loss: 5.3865 - val_accuracy: 0.0986\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7699 - accuracy: 0.7474 - val_loss: 5.5005 - val_accuracy: 0.0982\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7592 - accuracy: 0.7504 - val_loss: 5.5452 - val_accuracy: 0.1015\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7452 - accuracy: 0.7553 - val_loss: 5.6403 - val_accuracy: 0.0992\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7348 - accuracy: 0.7590 - val_loss: 5.6884 - val_accuracy: 0.0992\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.7232 - accuracy: 0.7641 - val_loss: 5.7480 - val_accuracy: 0.0963\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7124 - accuracy: 0.7666 - val_loss: 5.8001 - val_accuracy: 0.0992\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7003 - accuracy: 0.7709 - val_loss: 5.8899 - val_accuracy: 0.0961\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6920 - accuracy: 0.7761 - val_loss: 5.9332 - val_accuracy: 0.0972\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6807 - accuracy: 0.7779 - val_loss: 5.9994 - val_accuracy: 0.0988\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.6693 - accuracy: 0.7829 - val_loss: 6.0740 - val_accuracy: 0.0969\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6619 - accuracy: 0.7849 - val_loss: 6.1983 - val_accuracy: 0.0978\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6537 - accuracy: 0.7867 - val_loss: 6.1841 - val_accuracy: 0.0962\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6416 - accuracy: 0.7929 - val_loss: 6.2621 - val_accuracy: 0.0965\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6334 - accuracy: 0.7948 - val_loss: 6.3629 - val_accuracy: 0.0987\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6236 - accuracy: 0.7980 - val_loss: 6.4378 - val_accuracy: 0.0969\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6151 - accuracy: 0.7991 - val_loss: 6.4946 - val_accuracy: 0.0974\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.6043 - accuracy: 0.8047 - val_loss: 6.5579 - val_accuracy: 0.0969\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5978 - accuracy: 0.8058 - val_loss: 6.6648 - val_accuracy: 0.0961\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.5874 - accuracy: 0.8102 - val_loss: 6.7023 - val_accuracy: 0.0986\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5783 - accuracy: 0.8130 - val_loss: 6.7684 - val_accuracy: 0.1008\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.5727 - accuracy: 0.8171 - val_loss: 6.8650 - val_accuracy: 0.0978\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.5634 - accuracy: 0.8184 - val_loss: 6.8591 - val_accuracy: 0.0992\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5569 - accuracy: 0.8218 - val_loss: 6.9586 - val_accuracy: 0.0983\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5477 - accuracy: 0.8237 - val_loss: 7.0858 - val_accuracy: 0.1001\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.5387 - accuracy: 0.8272 - val_loss: 7.1323 - val_accuracy: 0.0972\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5323 - accuracy: 0.8279 - val_loss: 7.2004 - val_accuracy: 0.0979\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5236 - accuracy: 0.8328 - val_loss: 7.2246 - val_accuracy: 0.0957\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5152 - accuracy: 0.8346 - val_loss: 7.3367 - val_accuracy: 0.0973\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.5104 - accuracy: 0.8358 - val_loss: 7.4386 - val_accuracy: 0.0962\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.5020 - accuracy: 0.8395 - val_loss: 7.4863 - val_accuracy: 0.0995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe173f2b7c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در واقع، شما حتی نیازی به انجام این کار با داده‌های MNIST ندارید - فقط می‌توانید ورودی‌های نویز سفید و برچسب‌های تصادفی ایجاد کنید.\n",
    "- تا زمانی که پارامترهای کافی داشته باشد، می‌توانید مدلی را نیز روی آن قرار دهید.\n",
    "- در نهایت فقط ورودی‌های خاصی را حفظ می‌کند، دقیقاً مانند فرهنگ لغت پایتون.\n",
    "\n",
    "- اگر اینطور است، \n",
    "\n",
    "    - پس چگونه مدل‌های یادگیری عمیق اصلاً تعمیم می‌یابند؟ \n",
    "\n",
    "    - اگر آنها نهایتا یک تصویر از ورودی به خروجی یاد می‌گیرند، چطور با داده‌های جدید که تا به حال ندیده‌اند برخورد می‌کنند؟ \n",
    "همانطور که مشخص است، ماهیت تعمیم در یادگیری عمیق نسبتاً ارتباط کمی با خود مدل‌های یادگیری عمیق دارد و ارتباط زیادی با ساختار اطلاعات در دنیای واقعی دارد."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### فرضیه منیفلد\n",
    "\n",
    "مسئله دسته‌بندی در مجموعه داده‌ی MNIST را در نظر بگیرید.\n",
    "ورودی طبقه‌بندی‌کننده MNIST (قبل از پیش‌پردازش) یک آرایه ۲۸×۲۸ از اعداد صحیح بین ۰ تا ۲۵۵ است.\n",
    "- بنابراین تعداد کل مقادیر ورودی ممکن 256 به توان 784 است که بسیار بیشتر از تعداد اتم‌های جهان است!\n",
    "- با این حال، تعداد بسیار کمی از این ورودی‌ها مانند نمونه‌های معتبر MNIST به نظر می‌رسند: \n",
    "\n",
    "    - ارقام دست‌نویس واقعی فقط یک فضای فرعی کوچک از فضای والد همه آرایه‌های ممکن 28 × 28 با نوع داده‌ی uint8 را اشغال می‌کنند.\n",
    "\n",
    "    - علاوه بر این، این زیرفضا فقط مجموعه‌ای از نقاط نیست که به‌طور تصادفی در فضای والد قرار داشته باشند: آنها بسیار ساختارمند هستند.\n",
    "    - continuous: اگر نمونه‌ای را بردارید و کمی آن را اصلاح کنید، همچنان به عنوان همان رقم دست‌نویس قابل تشخیص است.\n",
    "    - connected: \n",
    "\n",
    "    - علاوه بر این، تمام نمونه‌های موجود در زیرفضای معتبر توسط مسیرهای همواری که از طریق زیرفضا می‌گذرد، به هم متصل می‌شوند.\n",
    "\n",
    "    - این بدان معنی است که اگر دو رقم تصادفی MNIST A و B را انتخاب کنید، دنباله‌ای از تصاویر \"واسطه\" وجود دارد که A را به B تبدیل می‌کنند، به طوری که دو رقم متوالی بسیار نزدیک به یکدیگر هستند (شکل 5.7 را ببینید).\n",
    "\n",
    "    - شاید چند شکل مبهم نزدیک به مرز بین دو کلاس وجود داشته باشد، اما حتی این اشکال همچنان بسیار شبیه به رقم هستند.\n",
    "\n",
    "![Different MNIST digits gradually morphing into one another, showing that the space of handwritten digits forms a “manifold.” This image was generated using code from chapter 12.](img/05-07.png)\n",
    "\n",
    "از نظر فنی، می‌توانید بگویید که ارقام دست‌نویس یک _مانیفولد_ را در فضای آرایه‌های ممکن 28 × 28 با نوع داده‌ی uint8 تشکیل می‌دهند.\n",
    "- تعریف: «منیفولد» یک زیرفضای با ابعاد پایین‌تر از یک فضای والد است که به صورت محلی شبیه به یک فضای خطی (اقلیدسی) است.\n",
    "\n",
    "    - به عنوان مثال، یک منحنی صاف در صفحه یک منیفولد 1 بعدی در یک فضای دو بعدی است، زیرا برای هر نقطه از منحنی، می‌توانید یک مماس رسم کنید (منحنی را می‌توان با یک خط در هر نقطه تقریب زد).\n",
    "\n",
    "    - یک سطح صاف در یک فضای سه بعدی یک منیفولد دو بعدی است.\n",
    "\n",
    "به طور کلی، فرضیه _منیفولد_ فرض می‌کند که همه داده‌های طبیعی روی یک منیفولد کم‌بعد در فضای با ابعاد بالا که در آن کدگذاری می‌شوند، قرار دارند.\n",
    "- این یک جمله بسیار قوی در مورد ساختار اطلاعات در جهان است.\n",
    "- تا آنجایی که ما می‌دانیم، صحیح و دقیق است، و به همین دلیل است که یادگیری عمیق کار می‌کند.\n",
    "- این برای ارقام MNIST، بلکه برای چهره انسان، مورفولوژی درخت، صداهای صدای انسان و حتی زبان طبیعی نیز صادق است.\n",
    "\n",
    "فرضیه منیفلد دلالت بر آن دارد\n",
    "\n",
    "* مدل‌های یادگیری ماشینی فقط باید فضاهای فرعی نسبتاً ساده، کم‌بعد و بسیار ساخت‌یافته را در فضای ورودی بالقوه خود (منیفولدهای پنهان `latent manifolds`) قرار دهند.\n",
    "* در یکی از این منیفولدها، همیشه می‌توان بین دو ورودی _interpolate کرد، یعنی از طریق یک مسیر پیوسته که در طول آن همه نقاط روی منیفولد قرار می‌گیرند، یکی به دیگری تغییر شکل داد.\n",
    "\n",
    "توانایی درونیابی بین نمونه‌ها کلید درک مفهوم تعمیم در یادگیری عمیق است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### درون‌یابی به عنوان منبع تعمیم\n",
    "\n",
    "اگر با نقاط داده‌ای کار می‌کنید که می‌توانند درون یابی شوند، می‌توانید نقاطی را که قبلاً هرگز ندیده‌اید، با ربط دادن آن‌ها به نقاط دیگری که در نزدیکی منیفولد قرار دارند، درک کنید.\n",
    "- به عبارت دیگر، شما می‌توانید با استفاده از یک _نمونه از فضا به کل بودن فضا پی ببرید.\n",
    "- برای پر کردن جاهای خالی (تشخیص نمونه‌های نادیده) می‌توانید از درون‌یابی استفاده کنید.\n",
    "\n",
    "توجه داشته باشید که درون یابی در منیفولد نهان با درون یابی خطی در فضای مادر متفاوت است، همانطور که در شکل 5.8 نشان داده شده است.\n",
    "- به عنوان مثال، میانگین پیکسل بین دو رقم MNIST معمولا یک رقم معتبر نیست.\n",
    "\n",
    "![Difference between linear interpolation and interpolation on the latent manifold. ](img/05-08.png)\n",
    "- Every point on the latent manifold of digits is a valid digit, but the average of two digits usually isn’t.\n",
    "\n",
    "بسیار مهم است، در حالی که یادگیری عمیق از طریق درون یابی بر روی یک تقریب آموخته شده از منیفولد داده به تعمیم دست می‌یابد، این اشتباه است که فرض کنیم درونیابی همه چیز برای تعمیم است.\n",
    "\n",
    "    - تذکر: درون یابی فقط می‌تواند به شما کمک کند چیزهایی را که بسیار نزدیک به آنچه قبلا دیده‌اید درک کنید: تعمیم محلی را فعال می‌کند.\n",
    "\n",
    "#### چرا یادگیری عمیق کار می‌کند؟\n",
    "\n",
    "استعاره توپ کاغذی مچاله شده از فصل 2 را به خاطر دارید؟\n",
    "- یک ورق کاغذ یک منیفولد دو بعدی را در فضای سه بعدی نشان می‌دهد (شکل 5.9 را ببینید).\n",
    "- مدل یادگیری عمیق ابزاری برای باز کردن توپ‌های کاغذی است، یعنی برای باز کردن منیفولدهای نهفته.\n",
    "\n",
    "![Uncrumpling a complicated manifold of data](img/05-09.png)\n",
    "\n",
    "یک مدل یادگیری عمیق اساساً یک منحنی با ابعاد بسیار بالا است \n",
    "\n",
    "    - منحنی صاف و پیوسته \n",
    "\n",
    "    - مطابق با محدودیت‌های اضافی در ساختار مدل که از معماری شبکه نشات می‌گیرد.\n",
    "- شبکه آن منحنی از طریق گرادیان نزولی، به صورت هموار و تدریجی به نقاط داده برازش می‌دهد.\n",
    "- به عبارت دیگر، یادگیری عمیق یک منحنی بزرگ و پیچیده - یک منیفولد – را می‌گیرد و به تدریج پارامترهای آن را تنظیم می‌کند تا بر داده‌های آموزشی مطابقت یابد.\n",
    "\n",
    "این منحنی شامل پارامترهای کافی است که می‌تواند با هر چیزی مطابقت داشته باشد \n",
    "\n",
    "    - در واقع، اگر به مدل خود اجازه دهید به اندازه کافی تمرین کند، در نهایت داده‌های آموزشی خود را صرفاً حفظ می‌کند و به هیچ وجه تعمیم نمی‌یابد.\n",
    "- فرضیه منیفلد: داده‌های مورد نظر برای مدل‌سازی یک منیفولد بسیار ساختار یافته و کم بعد در فضای ورودی هستند.\n",
    "- از آنجایی که مطابقت منحنی مدل شما با داده‌های آموزشی به تدریج و به آرامی در طول زمان و با پیشرفت روش گرایان نزولی اتفاق می‌افتد، یک نقطه میانی در طول آموزش وجود خواهد داشت که در آن مدل تقریباً منیفولد طبیعی داده‌ها را تقریب می‌کند.\n",
    "    - - به این ترتیب، مدل قادر خواهد بود ورودی‌های دیده نشده را از طریق درون یابی بین ورودی‌های آموزشی درک کند.\n",
    "\n",
    "    - این موضوع در شکل 5.10 مشاهده می‌کنید.\n",
    "\n",
    "![Going from a random model to an overfit model, and achieving a robust fit as an intermediate state](img/05-10.png)\n",
    "\n",
    "در کنار توانایی بالای مدل‌های یادگیری عمیق برای یادگیری، چند نکته باید مورد توجه باشد:\n",
    "\n",
    "    * مدل‌های یادگیری عمیق نقشه‌برداری هموار و پیوسته را از ورودی‌ها به خروجی‌هایشان پیاده‌سازی می‌کنند.\n",
    "\n",
    "    - بنابراین منیفلدها باید صاف و پیوسته باشد زیرا بنا به ضرورت باید مشتق‌پذیر باشند (در غیر این صورت نمی‌توانستید نزول گرادیان را انجام دهید).\n",
    "\n",
    "    * معماری شبکه باید با «شکل» اطلاعات در داده‌های آموزشی مطابقت داشته باشد و بازتاب داده‌ها باشند.\n",
    "\n",
    "    - این مورد به ویژه در مورد مدل‌های پردازش تصویر (مورد بحث در فصل‌های 8 و 9) و مدل‌های پردازش توالی (فصل 10) صادق است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### داده‌های آموزشی بسیار مهم است\n",
    "\n",
    "گرچه یادگیری عمیق برای یادگیری منیفلد مناسب است، قدرت تعمیم بیشتر نتیجه ساختار طبیعی داده‌های شما است:\n",
    "    - فقط در صورتی می‌توانید تعمیم دهید که داده‌های شما منیفولدی باشد که نقاط را بتوان درون‌یابی کرد.\n",
    "    - هرچه ویژگی‌های شما آموزنده‌تر و نویز کمتری داشته باشد، بهتر می‌توانید تعمیم دهید، زیرا فضای ورودی شما ساده‌تر و ساختار بهتری خواهد داشت.\n",
    "    - تنظیم داده‌ها و مهندسی ویژگی برای تعمیم ضروری است.\n",
    "    - داده‌ها باید نمونه‌برداری متراکم از فضای ورودی باشند، مخصوصا در نزدیکی مرزهای تصمیم‌گیری.\n",
    "        - شکل 5.11 را ببینید.\n",
    "    - با یک نمونه برداری به اندازه کافی متراکم، می‌توان ورودی‌های جدید را با درون‌یابی بین ورودی‌های آموزشی گذشته درک کرد.\n",
    "        - در اینجا نیازی به استفاده از عقل، استدلال انتزاعی یا دانش خارجی در مورد جهان وجود ندارد!\n",
    "\n",
    "![A dense sampling of the input space is necessary in order to learn a model capable of accurate generalization.](img/05-11.png)\n",
    "\n",
    "- بهترین راه برای بهبود یک مدل یادگیری عمیق، آموزش آن بر روی داده‌های بیشتر یا داده‌های بهتر است \n",
    "\n",
    "    - البته، اضافه کردن داده‌های نویزی یا نادرست به تعمیم آسیب می‌رساند.\n",
    "\n",
    "    - پوشش متراکم تری از منیفولد داده ورودی، مدلی را به دست می‌دهد که تعمیم بهتری دارد.\n",
    "\n",
    "    - هرگز نباید انتظار داشته باشید که یک مدل یادگیری عمیق چیزی بیش از درون یابی خام بین نمونه‌های آموزشی خود انجام دهد و بنابراین باید هر کاری که می‌توانید انجام دهید تا درون یابی را تا حد امکان آسان کنید.\n",
    "- تنها چیزی که در یک مدل یادگیری عمیق می‌یابید، چیزی است که در آن قرار می‌دهید: \n",
    "     1.  دانش پیشین که در طراحی معماری شبکه جاسازی شده است.\n",
    "     2. داده‌های آموزشی.\n",
    "\n",
    "- اگر افزایش تعداد و کیفیت داده‌ها برای مقابله با بیش‌برازش میسر نباشد، بهترین راه حل بعدی تعدیل مقدار اطلاعاتی است که مدل شما مجاز به ذخیره آن است (اضافه کردن محدودیت‌هایی برای صاف بودن منحنی مدل)\n",
    "- اگر شبکه‌ای فقط توانایی حفظ تعداد کمی از الگوها یا الگوهای بسیار منظم را داشته باشد، فرآیند بهینه‌سازی آن را وادار می‌کند تا بر برجسته ترین الگوها تمرکز کند که شانس بیشتری برای تعمیم خوب دارند.\n",
    "- فرآیند مبارزه با بیش‌برازش متناسب از این طریق _`regularization` _ نامیده می‌شود.\n",
    "    - در مورد آن بعدا صحبت می‌کنیم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ارزیابی مدل‌های یادگیری ماشینی\n",
    "شما فقط می‌توانید آنچه را که می‌توانید مشاهده کنید، کنترل کنید.\n",
    "    - چطور می‌توانیم توانایی تعمیم را اندازه‌گیری کنیم؟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### مجموعه‌های آموزشی، اعتبارسنجی و تست\n",
    "\n",
    "ارزیابی یک مدل همیشه به تقسیم داده‌های موجود به سه مجموعه خلاصه می‌شود: آموزش، اعتبار سنجی و آزمایش.\n",
    "- شما بر روی داده‌های آموزشی آموزش می‌بینید و مدل خود را بر روی داده‌های اعتبارسنجی ارزیابی می‌کنید.\n",
    "- هنگامی که مدل شما آماده شد، آن را برای آخرین بار روی داده‌های آزمایشی آزمایش می‌کنید\n",
    "\n",
    "     داده‌های آزمایش تا حد امکان شبیه به داده‌های دنیای واقعی هستند.\n",
    "- سپس می‌توانید مدل را مستقر کنید (deployment).\n",
    "\n",
    "چرا فقط دو مجموعه نداشته باشیم: یک مجموعه آموزشی و یک مجموعه تست؟\n",
    "\n",
    "    - شما روی داده‌های آموزشی آموزش می‌بینید و روی داده‌های آزمون ارزیابی می‌کنید.\n",
    "\n",
    "    - خیلی ساده‌تر هست! ولی...\n",
    "\n",
    "دلیل آن این است که توسعه یک مدل همیشه مستلزم تنظیم پیکربندی (configuration) آن است که در آن _hyperparameters` تعیین می‌شوند: \n",
    "- انتخاب تعداد لایه‌ها\n",
    "- اندازه لایه‌ها \n",
    "- این تنظیم را با استفاده از سیگنال بازخورد از عملکرد مدل روی داده‌های اعتبارسنجی انجام می‌دهید.\n",
    "\n",
    "- خطر: تنظیم پیکربندی مدل بر اساس عملکرد آن در مجموعه اعتبارسنجی می‌تواند به سرعت منجر به *بیش‌برازش* با مجموعه اعتبارسنجی شود، \n",
    "\n",
    "    - حتی اگر مدل شما هرگز مستقیماً روی آن آموزش داده نشود.\n",
    "\n",
    "    - مفهوم نشت اطلاعات \n",
    "\n",
    "    - هر بار که یک ابرپارامتر از مدل خود را بر اساس عملکرد مدل در مجموعه اعتبارسنجی تنظیم می‌کنید، اطلاعاتی در مورد داده‌های اعتبارسنجی به مدل نشت می‌کند.\n",
    "\n",
    "    - با تکرار این فرآیند روی داده‌های اعتبارسنجی دچار بیش‌برازش می‌شوید!\n",
    "\n",
    "    - مقدار قابل توجهی از اطلاعات مربوط به مجموعه اعتبار‌سنجی به مدل درز خواهد کرد.\n",
    "- شما به عملکرد روی داده‌های کاملاً جدید اهمیت می‌دهید، نه به داده‌های اعتبارسنجی، بنابراین باید از یک مجموعه داده کاملاً متفاوت و هرگز دیده نشده برای ارزیابی مدل استفاده کنید: مجموعه داده آزمایشی.\n",
    "- مدل شما نباید به _هیچ_ اطلاعاتی درباره مجموعه تست دسترسی داشته باشد، حتی به صورت غیرمستقیم وگرنه معیار تعمیم شما ناقص خواهد بود."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### روش های تقسیم داده‌ها به مجموعه‌های آموزشی، اعتبار سنجی و آزمایش: \n",
    "    - `holdout` ساده،\n",
    "    - اعتبار‌سنجی `K-fold`،\n",
    "    - اعتبارسنجی `K-fold` تکرار شونده همراه با درهم‌ریختن."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### اعتبار سنجی  `holdout` ساده\n",
    "بخشی از داده‌های خود را به عنوان مجموعه آزمایشی جدا کنید.\n",
    "- بر روی داده‌های باقی مانده آموزش دهید و روی مجموعه تست ارزیابی کنید.\n",
    "- همانطور که در قسمت‌های قبلی دیدید، برای جلوگیری از درز اطلاعات، نباید مدل خود را بر اساس مجموعه تست تنظیم کنید و بنابراین باید یک مجموعه اعتبار سنجی رزرو کنید.\n",
    "\n",
    "![Simple holdout validation split](img/05-12.png)\n",
    "\n",
    "-مزایا و معایب\n",
    "     - ساده است.\n",
    "     - اگر داده‌های کمی در دسترس باشد، اعتبارسنجی و مجموعه‌های آزمایشی شما ممکن است حاوی نمونه‌های بسیار کمی باشد که از نظر آماری معرف داده‌های موجود نباشد.\n",
    "     - روش تشخیص: اگر قبل تقسیم داده‌ها را به صورت تصادفی بر بزنیم و این کار را چند بار تکرار کنیم، به معیارهای بسیار متفاوتی از عملکرد مدل منجر ‌می‌شود.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### اعتبار K-fold\n",
    "با این روش، داده‌های خود را به پارتیشن‌های K با اندازه مساوی تقسیم می‌کنید.\n",
    "\n",
    "    - برای هر پارتیشن i، یک مدل را روی پارتیشن‌های K - 1 باقی مانده آموزش دهید و آن را در پارتیشن i ارزیابی کنید.\n",
    "\n",
    "    - نمره نهایی شما پس از آن میانگین نمرات K به دست آمده است.\n",
    "\n",
    "    - این روش زمانی مفید است که عملکرد مدل شما واریانس قابل توجهی را بر اساس تقسیم آموزش-آزمون نشان دهد.\n",
    "\n",
    "![K-fold cross-validation with K=3](img/05-13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### اعتبار‌سنجی K-fold تکرار شونده با درهم‌زدن\n",
    "این یکی برای موقعیت‌هایی است که در آن داده‌های نسبتا کمی در دسترس دارید و باید مدل خود را تا حد امکان دقیق ارزیابی کنید.\n",
    "\n",
    "    - مناسب برای مسابقات کگل\n",
    "\n",
    "    - شامل استفاده از اعتبار سنجی K-fold چندین بار، به هم زدن داده‌ها هر بار قبل از تقسیم آن به K راه است.\n",
    "\n",
    "    - امتیاز نهایی میانگین نمرات به دست آمده در هر مرحله از اعتبارسنجی K-fold است.\n",
    "\n",
    "    - توجه داشته باشید که در نهایت مدل‌ها $P*K$ را آموزش و ارزیابی ‌کنید ($P$ تعداد تکرارهاست)، \n",
    "\n",
    "    - پیاده‌سازی بسیار پرهزینه است!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### عبور از خط پایه  (`baseline`)\n",
    "علاوه بر پروتکل‌های ارزیابی متفاوتی که در دسترس دارید، آخرین چیزی که باید در مورد آن بدانید استفاده از خطوط پایه است.\n",
    "\n",
    "- اگر بگویند دقت مدل 15% روی مجموعه داده‌های اعتبارسنجی است، خوب هست؟\n",
    "\n",
    "    - قبل از شروع کار با مجموعه داده، همیشه باید یک خط پایه را انتخاب کنید که سعی کنید آن را شکست دهید.\n",
    "\n",
    "    - اگر از این آستانه عبور کنید، می‌دانید که کاری را درست انجام می‌دهید.\n",
    "\n",
    "    - این خط پایه می‌تواند عملکرد یک طبقه‌بندی تصادفی یا عملکرد ساده‌ترین تکنیک غیر از یادگیری ماشین باشد.\n",
    "\n",
    "    - مثال: در مثال طبقه‌بندی رقمی MNIST، یک خط پایه ساده، دقت اعتبارسنجی بیشتر از 0.1 (طبقه‌بندی‌کننده تصادفی) است. \n",
    "\n",
    "    - در مثال IMDB، دقت اعتبارسنجی بیشتر از 0.5 خواهد بود.\n",
    "\n",
    "    - در مثال رویترز، به دلیل عدم تعادل طبقاتی، حدود 0.18-0.19 خواهد بود.\n",
    "\n",
    "    - اگر مسئله طبقه‌بندی باینری دارید که در آن 90% نمونه‌ها متعلق به کلاس A و 10% متعلق به کلاس B هستند، طبقه‌بندی‌کننده‌ای که همیشه A را پیش‌بینی می‌کند از قبل به 0.9 در دقت اعتبار می‌رسد!\n",
    "\n",
    "    - داشتن خط مبنای زمانی ضروری است که در حال شروع حل مسئله‌ای برای اولین بار هستید.\n",
    "\n",
    "    - اگر نمی‌توانید راه‌حل‌های بی‌اهمیت را شکست دهید، مدل شما بی‌ارزش است! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### چیزهایی که باید در مورد ارزیابی مدل در نظر داشت\n",
    "\n",
    "هنگام انتخاب پروتکل ارزیابی به موارد زیر توجه داشته باشید:\n",
    "\n",
    "* _نمایندگی داده ها_—شما می‌خواهید هم مجموعه آموزشی و هم مجموعه تست شما معرف داده‌های موجود باشد.\n",
    "\n",
    "    - به عنوان مثال، اگر می‌خواهید تصاویر ارقام را طبقه‌بندی کنید، و از آرایه‌ای از نمونه‌ها شروع می‌کنید که نمونه‌ها بر اساس کلاس آنها مرتب شده‌اند، 80% اول آرایه را به عنوان مجموعه آموزشی خود در نظر می‌گیرید و بقیه را در نظر بگیرید. 20\\% به عنوان مجموعه تست شما باعث می‌شود مجموعه آموزشی شما فقط شامل کلاس‌های 0-7 باشد، در حالی که مجموعه تست شما فقط شامل کلاس‌های 8-9 خواهد بود.\n",
    "\n",
    "    - به همین دلیل، معمولاً باید داده‌های خود را قبل از تقسیم به مجموعه‌های آموزشی و آزمایشی، به صورت تصادفی به هم بزنید.\n",
    "* _در نظر گرفتن زمان_—اگر می‌خواهید آینده را با توجه به گذشته پیش‌بینی کنید (مثلاً آب‌وهوای فردا، حرکت سهام و غیره)، نباید قبل از تقسیم داده‌هایتان به‌طور تصادفی آن‌ها را به هم بزنید، وگرنه نشت اطلاعاتی از آینده به گذشته رخ می‌دهد. \n",
    "\n",
    "    - در چنین شرایطی، همیشه باید مطمئن شوید که تمام داده‌های مجموعه آزمایشی بعد (`posterior`) مجموعه داده‌های آموزشی هستند.\n",
    "* _افزونگی در داده‌ها_—اگر برخی از نقاط داده در داده‌های شما دو بار ظاهر شوند (تقریباً با داده‌های دنیای واقعی رایج است)، سپس به هم زدن داده‌ها و تقسیم آن به یک مجموعه آموزشی و یک مجموعه اعتبار سنجی منجر به افزونگی بین مجموعه‌های آموزشی و اعتبار سنجی می‌شود. \n",
    "\n",
    "    - در واقع، بخشی از داده‌های آموزشی خود را آزمایش خواهید کرد، که بدترین کاری است که می‌توانید انجام دهید! \n",
    "\n",
    "    - مطمئن شوید که مجموعه آموزشی و مجموعه اعتبار سنجی شما از هم *جدا* هستند.\n",
    "\n",
    "رویکرد کلی باید به این صورت باشد که اول باید شاهد `overfit` شدن مدل خود باشید و در ادامه به مصالحه بین بهینه‌سازی و تعمیم برسید.\n",
    "\n",
    "    - از آنجایی که از قبل نمی‌دانید مرز مناسب کجاست، باید از آن عبور کنید تا آن را پیدا کنید!\n",
    "\n",
    "    - سپس برای بهبود تعمیم وارد عمل شویم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     \n",
    "### سه حالت در شروع حل مسئله \n",
    "     1. مدل آموزش نمی‌بیند: خطای آموزش شما به مرور زمان کاهش نمی‌یابد.\n",
    "        - گاهی اوقات آموزش شروع نمی‌شود یا خیلی زود متوقف می‌شود.\n",
    "     2. آموزش به خوبی شروع می‌شود، اما مدل شما به خوبی تعمیم نمی‌یابد و نمی‌توانید خط پایه را شکست دهید.\n",
    "     3. خطای آموزش و اعتبارسنجی هر دو به مرور زمان کاهش می‌یابد و از خط پایه عبور می‌کنیم ولی دچار بیش‌برازش نمی‌شویم."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### حل مشکلات در برخورد اولیه در ایجاد مصالحه\n",
    "- همیشه می‌توان بر این مشکل غلبه کرد.\n",
    "\n",
    "    - باید پارامترهای گرادیان نزولی را تنظیم کنیم.\n",
    "\n",
    "    - انتخاب بهینه‌ساز مناسب، \n",
    "\n",
    "    - توزیع مقادیر اولیه در وزن‌های مدل، \n",
    "\n",
    "    - نرخ یادگیری *\n",
    "\n",
    "    - اندازه دسته *.\n",
    "- معمولاً تنظیم نرخ یادگیری و اندازه دسته و در عین حال ثابت نگه داشتن بقیه پارامترها کافی است.\n",
    "\n",
    "مثال: MNIST \n",
    "\n",
    "**آموزش مدل MNIST با نرخ یادگیری نادرست بالا**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 710.2678 - accuracy: 0.3105 - val_loss: 2.5704 - val_accuracy: 0.2838\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 4.7851 - accuracy: 0.2219 - val_loss: 2.5500 - val_accuracy: 0.2272\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 3.4537 - accuracy: 0.2394 - val_loss: 2.4801 - val_accuracy: 0.2782\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.6900 - accuracy: 0.2394 - val_loss: 2.1549 - val_accuracy: 0.2315\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.6728 - accuracy: 0.2534 - val_loss: 2.1577 - val_accuracy: 0.2768\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.6551 - accuracy: 0.2620 - val_loss: 2.5337 - val_accuracy: 0.2966\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.7431 - accuracy: 0.2809 - val_loss: 5.9456 - val_accuracy: 0.2612\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.4603 - accuracy: 0.2750 - val_loss: 2.0314 - val_accuracy: 0.2472\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.4722 - accuracy: 0.2901 - val_loss: 2.0494 - val_accuracy: 0.2515\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.4813 - accuracy: 0.2772 - val_loss: 2.1862 - val_accuracy: 0.2929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff0ac269100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این مدل به سرعت به دقت آموزشی و اعتبارسنجی در محدوده 30٪ تا 40٪ می‌رسد، اما نمی‌تواند از آن عبور کند.\n",
    "- بیایید سعی کنیم نرخ یادگیری را به مقدار معقول تر 1e-2 کاهش دهیم.\n",
    "\n",
    "**همان مدل با نرخ یادگیری مناسب**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3989 - accuracy: 0.1005 - val_loss: 2.4022 - val_accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff0aca58460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این مدل اکنون قادر به آموزش است.\n",
    "\n",
    "اگر در موقعیت مشابهی قرار گرفتید، سعی کنید\n",
    "\n",
    "* کاهش یا افزایش نرخ یادگیری.\n",
    "- نرخ یادگیری بسیار بالا ممکن است منجر به به‌روزرسانی‌هایی شود که از تناسب مناسب فراتر می‌رود، مانند مثال قبل، و نرخ یادگیری بسیار پایین ممکن است آموزش را چنان کند کند که به نظر می‌رسد متوقف می‌شود.\n",
    "* افزایش اندازه دسته.\n",
    "- دسته‌ای با نمونه‌های بیشتر منجر به گرادیان‌هایی می‌شود که اطلاعات بیشتری دارند و نویز کمتری دارند (واریانس کمتر).\n",
    "\n",
    "- برای حل مشکل دوم که سخت‌ترین مشکل هست، راه ساده‌ای وجود ندارد:\n",
    "\n",
    "    - مدل شما آموزش می‌دهد اما تعمیم نمی‌یابد.\n",
    "\n",
    "    - این نشان می‌دهد که *چیزی اساساً در رویکرد شما اشتباه است*.\n",
    "\n",
    "    - ممکن است داده‌های ورودی که استفاده می‌کنید به سادگی حاوی اطلاعات کافی برای پیش‌بینی اهداف شما نباشد:\n",
    "\n",
    "    - این همان چیزی است که قبلاً هنگامی که ما سعی کردیم مدل MNIST را در جایی که برچسب‌ها به هم می‌پیوندند قرار دهیم، اتفاق افتاد: مدل به خوبی تمرین می‌کرد، اما دقت اعتبارسنجی در 10٪ باقی می‌ماند، زیرا تعمیم با چنین مجموعه داده‌ای آشکارا غیرممکن بود.\n",
    "        - همچنین ممکن است نوع مدلی که استفاده می‌کنید برای مسئله موجود مناسب نباشد:\n",
    "            - به عنوان مثال، استفاده از معماری متصل و متراکم (fully connected) برای مسئله سری زمانی. \n",
    "            - هر کاربردی معماری مناسبی می‌طلبد.\n",
    "\n",
    "- برای حل مشکل سوم، یعنی حالتی که موفق شدید به مدلی برسید که توانایی یادگیری دارد و از خط پایه روی داده‌های اعتبارسنجی عبور می‌کند ولی دچار بیش‌برازش نمی‌شود، باید مدل خود را تقویت کنید. \n",
    "- به عبارت دیگر مشکل از قدرت بازنمایی مدل شماست: به یک مدل بزرگ‌تر نیاز دارید، مدلی با ظرفیت بیشتر، یعنی مدلی که می‌تواند اطلاعات بیشتری را ذخیره کند.\n",
    "- افزایش تعداد لایه‌ها یا تعداد واحد‌ها در لایه‌ها یا لایه‌های قدرتمند‌تر\n",
    "\n",
    "- مثال: مدل کوچک زیر را در نظر بگیرید - یک رگرسیون لجستیک ساده - که بر روی پیکسل‌های MNIST آموزش داده شده است.\n",
    "\n",
    "**یک رگرسیون لجستیک ساده در MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.6679 - accuracy: 0.8334 - val_loss: 0.3572 - val_accuracy: 0.9048\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.9031 - val_loss: 0.3072 - val_accuracy: 0.9141\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3159 - accuracy: 0.9119 - val_loss: 0.2897 - val_accuracy: 0.9197\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2993 - accuracy: 0.9158 - val_loss: 0.2798 - val_accuracy: 0.9215\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2897 - accuracy: 0.9192 - val_loss: 0.2742 - val_accuracy: 0.9238\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.9208 - val_loss: 0.2731 - val_accuracy: 0.9238\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.9228 - val_loss: 0.2684 - val_accuracy: 0.9267\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.9238 - val_loss: 0.2681 - val_accuracy: 0.9271\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.9253 - val_loss: 0.2652 - val_accuracy: 0.9276\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9255 - val_loss: 0.2656 - val_accuracy: 0.9276\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2665 - accuracy: 0.9257 - val_loss: 0.2630 - val_accuracy: 0.9280\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.9274 - val_loss: 0.2622 - val_accuracy: 0.9293\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.9277 - val_loss: 0.2614 - val_accuracy: 0.9303\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2616 - accuracy: 0.9277 - val_loss: 0.2615 - val_accuracy: 0.9302\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.9291 - val_loss: 0.2611 - val_accuracy: 0.9289\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2592 - accuracy: 0.9289 - val_loss: 0.2612 - val_accuracy: 0.9298\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2584 - accuracy: 0.9291 - val_loss: 0.2619 - val_accuracy: 0.9305\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2571 - accuracy: 0.9296 - val_loss: 0.2616 - val_accuracy: 0.9298\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2564 - accuracy: 0.9301 - val_loss: 0.2615 - val_accuracy: 0.9302\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2555 - accuracy: 0.9299 - val_loss: 0.2606 - val_accuracy: 0.9305\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Effect of insufficient model capacity on loss curves](img/05-14.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff068fc0ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "به نظر می‌رسد معیارهای اعتبار سنجی به جای اینکه به اوج خود برسند و مسیرشان را معکوس کنند، متوقف می‌شوند، یا بسیار آهسته بهبود می‌یابند.\n",
    "- خطای اعتبارسنجی به 0.26 می‌رسد و دیگر بهبود نمی‌یابد.\n",
    "\n",
    "بیایید یک مدل بزرگتر را آموزش دهیم، یکی با دو لایه میانی با هر کدام 96 واحد:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.8990 - val_loss: 0.1833 - val_accuracy: 0.9478\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9514 - val_loss: 0.1278 - val_accuracy: 0.9629\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1137 - accuracy: 0.9656 - val_loss: 0.1059 - val_accuracy: 0.9697\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9740 - val_loss: 0.1055 - val_accuracy: 0.9709\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9795 - val_loss: 0.0941 - val_accuracy: 0.9734\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.0942 - val_accuracy: 0.9738\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9859 - val_loss: 0.0959 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0386 - accuracy: 0.9883 - val_loss: 0.0908 - val_accuracy: 0.9745\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9903 - val_loss: 0.0944 - val_accuracy: 0.9739\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 0.1030 - val_accuracy: 0.9744\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9928 - val_loss: 0.1139 - val_accuracy: 0.9739\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1205 - val_accuracy: 0.9743\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.1190 - val_accuracy: 0.9748\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.1235 - val_accuracy: 0.9745\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1271 - val_accuracy: 0.9747\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1223 - val_accuracy: 0.9774\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1340 - val_accuracy: 0.9747\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.1464 - val_accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1450 - val_accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "منحنی اعتبار سنجی اکنون دقیقاً همانطور که باید به نظر می‌رسد: مدل به سرعت جا می‌گیرد و پس از 8 دوره شروع به تنظیم بیش‌برازش می‌کند (شکل 5.15 را ببینید).\n",
    "\n",
    "![Validation loss for a model with appropriate capacity](img/05-15.png)\n",
    "\n",
    "- بعد از `overfit` وقت آن است که تمرکز خود را روی حداکثر کردن تعمیم قرار دهید."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تنظیم مجموعه داده\n",
    "- یادآوری: تعمیم در یادگیری عمیق از ساختار پنهان داده‌ها سرچشمه می‌گیرد.\n",
    "- نکات مرتبط با مسئله یا داده‌ها در یادگیری عمیق:\n",
    "\n",
    "    - اگر داده‌های شما امکان درون‌یابی هموار بین نمونه‌ها را فراهم می‌کند، می‌توانید یک مدل یادگیری عمیق را آموزش دهید که تعمیم می‌دهد.\n",
    "\n",
    "    - اگر مسئله شما نویزی یا از جنس مسائل گسسته است (مثلاً مرتب‌سازی لیست)، یادگیری عمیق به شما کمکی نمی‌کند.\n",
    "\n",
    "    - یادگیری عمیق برازش منحنی است، نه جادو.\n",
    "\n",
    "    - صرف تلاش و پول بیشتر برای جمع‌آوری داده‌ها تقریباً همیشه بازده سرمایه‌گذاری بسیار بیشتری را نسبت به هزینه کردن برای توسعه یک مدل بهتر به همراه دارد.\n",
    "\n",
    "    - مطمئن شوید که داده‌های کافی دارید.\n",
    "- به یاد داشته باشید که به یک _نمونه گیری متراکم_ از فضای ورودی-متقاطع-خروجی نیاز دارید.\n",
    "- داده‌های بیشتر مدل بهتری را به همراه خواهد داشت.\n",
    "- گاهی اوقات، مسايلی که در ابتدا غیرقابل حل به نظر می‌رسند، با مجموعه داده بزرگتر قابل حل می‌شوند.\n",
    "- خطاهای برچسب زدن را به حداقل برسانید - ورودی‌های خود را برای بررسی ناهنجاری‌ها تجسم کنید و برچسب‌های خود را تصحیح کنید.\n",
    "- داده‌های خود را پاک کنید و با مقادیر از دست رفته مقابله کنید.\n",
    "- اگر ویژگی‌های زیادی دارید و مطمئن نیستید که کدام یک واقعا مفید هستند، انتخاب ویژگی را انجام دهید.\n",
    "\n",
    "یک راه بسیار مهم برای بهبود پتانسیل تعمیم داده‌های شما، مهندسی ویژگی (`feature engineering`) است."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### مهندسی ویژگی\n",
    "\n",
    "- _مهندسی ویژگی_ فرآیند استفاده از دانش شما در مورد داده‌ها و الگوریتم یادگیری ماشین موجود است\n",
    "\n",
    "    - داده‌ها باید به گونه‌ای به مدل ارائه شوند که کار مدل را آسان تر کند.\n",
    "\n",
    "- مثال: فرض کنید در حال تلاش برای ایجاد مدلی هستید که بتواند تصویر یک ساعت را به عنوان ورودی بگیرد و بتواند زمان روز را خروجی دهد (شکل 5.16 را ببینید).\n",
    "\n",
    "![Feature engineering for reading the time on a clock](img/05-16.png)\n",
    "\n",
    "اگر می‌خواهید از پیکسل‌های خام تصویر به عنوان داده ورودی استفاده کنید، مشکل یادگیری ماشینی دشواری در دستان خود دارید.\n",
    "- برای حل آن به یک شبکه عصبی کانولوشنال نیاز دارید و باید مقدار زیادی از منابع محاسباتی را برای آموزش شبکه صرف کنید.\n",
    "\n",
    "اما اگر قبلاً مشکل را در سطح بالایی درک کرده باشید (می‌دانید چگونه انسان‌ها زمان را بر روی صفحه ساعت می‌خوانند)، می‌توانید ویژگی‌های ورودی بسیار بهتری برای الگوریتم یادگیری ماشین پیدا کنید: به عنوان مثال، نوشتن یک پنج خطی آسان است. اسکریپت پایتون برای دنبال کردن پیکسل‌های سیاه عقربه‌های ساعت و خروجی مختصات (x, y) نوک هر عقربه.\n",
    "- سپس یک الگوریتم یادگیری ماشینی ساده می‌تواند یاد بگیرد که این مختصات را با زمان مناسب روز مرتبط کند.\n",
    "\n",
    "حتی می‌توانید جلوتر بروید: یک تغییر مختصات انجام دهید و مختصات (x, y) را به صورت مختصات قطبی با توجه به مرکز تصویر بیان کنید.\n",
    "- ورودی شما به زاویه تتا هر عقربه ساعت تبدیل می‌شود.\n",
    "- در این مرحله، ویژگی‌های شما مشکل را چنان آسان می‌کند که نیازی به یادگیری ماشینی نیست. یک عملیات گرد کردن ساده و جستجوی فرهنگ لغت برای بازیابی زمان تقریبی روز کافی است.\n",
    "\n",
    "این ماهیت مهندسی ویژگی است: آسان کردن یک مشکل با بیان آن به روشی ساده تر.\n",
    "- منیفولد نهفته را صاف‌تر، ساده‌تر و سازمان‌دهی‌تر کنید.\n",
    "- انجام این کار معمولا مستلزم درک عمیق مشکل است.\n",
    "\n",
    "قبل از یادگیری عمیق، مهندسی ویژگی مهم‌ترین بخش گردش کار یادگیری ماشین بود، زیرا الگوریتم‌های کم عمق کلاسیک فضای فرضی کافی برای یادگیری ویژگی‌های مفید را نداشتند.\n",
    "- نحوه ارائه داده‌ها به الگوریتم برای موفقیت آن کاملاً حیاتی بود.\n",
    "- به عنوان مثال، قبل از موفقیت شبکه‌های عصبی کانولوشن در مسئله طبقه‌بندی رقمی MNIST، راه‌حل‌ها معمولاً بر اساس ویژگی‌های رمزگذاری‌شده مانند تعداد حلقه‌ها در یک تصویر رقمی، ارتفاع هر رقم در یک تصویر، هیستوگرام مقادیر پیکسل بود. ، و غیره.\n",
    "\n",
    "- خوشبختانه، یادگیری عمیق مدرن تا حد زیادی نیاز به مهندسی ویژگی‌ها را از بین می‌برد،\n",
    "- شبکه‌های عصبی قادر به استخراج خودکار ویژگی‌های مفید از داده‌های خام هستند. - اما از آن بی‌نیاز نیستیم:   \n",
    "    * ویژگی‌های خوب همچنان به شما امکان می‌دهد تا در عین استفاده از منابع کمتر، مشکلات را با ظرافت بیشتری حل کنید.  \n",
    "        - به عنوان مثال، حل مشکل خواندن صفحه ساعت با استفاده از یک شبکه عصبی کانولوشن مسخره خواهد بود!  \n",
    "    * ویژگی‌های خوب به شما امکان می‌دهد با داده‌های بسیار کمتر مسئله را حل کنید.  \n",
    "    * مناسب برای مسائلی که نمونه کم دارید.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### استفاده از توقف زودهنگام\n",
    "\n",
    "در یادگیری عمیق، ما همیشه از مدل‌هایی استفاده می‌کنیم که به شدت بیش‌برازش پارامتر هستند: آنها درجات آزادی بیشتری نسبت به حداقل لازم برای تناسب با منیفولد پنهان داده‌ها دارند.\n",
    "    - همیشه مدت‌ها قبل از رسیدن به حداقل خطای ممکن در داده‌های آموزشی، فرايند یادگیری را قطع می‌کنید (تعمیم).\n",
    "\n",
    "برای جلوگیری از دوباره کاری و صرف هزینه گران بازآموزی می‌توانید مدل خود را در پایان هر دوره با بهترین نتیجه تا کنون مقایسه کنید. در ادامه یا\n",
    "- بهترین نتیجه را به روز‌رسانی کنی، یا\n",
    "- به محض اینکه معیارهای اعتبارسنجی بهبود نیافتند، در حالی که بهترین حالت مدل شناخته شده را به خاطر می‌آورند، آموزش را قطع می‌کند.\n",
    "- در Keras، انجام این کار با یک فراخوانی `EarlyStopping` معمول است.\n",
    "\n",
    "### مدل خود را چابک کنید (`regularization`)\n",
    "\n",
    "تکنیک‌های چابک‌سازی مجموعه‌ای از تکنیک‌ها هستند که به طور فعال مانع از توانایی مدل برای تطبیق کامل با داده‌های آموزشی می‌شوند، با هدف اینکه مدل در طول اعتبارسنجی عملکرد بهتری داشته باشد.\n",
    "- به این کار «چابک‌سازی» مدل گفته می‌شود، زیرا تمایل دارد مدل را «ساده‌تر» و «منظم‌تر» کند یا منحنی آن را «صاف‌تر» و «عمومی‌تر» کند. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تکنیک‌های چابک‌سازی شبکه \n",
    "در ادامه روش‌هایی معرفی می‌شوند که برای چابک‌سازی شبکه عصبی می‌توان از آنها استفاده کرد.\n",
    "\n",
    "#### کاهش اندازه شبکه\n",
    "\n",
    "قبلاً آموخته‌اید که مدلی که خیلی کوچک باشد نمی‌تواند اطلاعات زیادی را در خود جای دهد.\n",
    "- ساده ترین راه برای کاهش اضافه برازش، کاهش اندازه مدل است (تعداد پارامترهای قابل یادگیری در مدل، تعیین شده توسط تعداد لایه‌ها و تعداد واحدها در هر لایه).\n",
    "- در عین حال، به خاطر داشته باشید که باید از مدل‌هایی استفاده کنید که پارامترهای کافی را داشته باشند که کمتر از آن مناسب نباشند: مدل شما نباید *گرسنه* باشد.\n",
    "- مصالحه‌ای بین _ظرفیت بیش‌برازش_ و _ظرفیت کافی_ وجود دارد.\n",
    "    - با لایه‌ها و پارامترهای نسبتاً کم شروع کنید و اندازه لایه‌ها را افزایش دهید یا لایه‌های جدید اضافه کنید تا زمانی که بازدهی کاهشی را با توجه به از دست دادن اعتبارسنجی مشاهده کنید.\n",
    "\n",
    "**مدل اصلی**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 3s 51ms/step - loss: 0.5352 - accuracy: 0.7854 - val_loss: 0.4045 - val_accuracy: 0.8693\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3267 - accuracy: 0.8935 - val_loss: 0.3131 - val_accuracy: 0.8862\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2340 - accuracy: 0.9225 - val_loss: 0.2903 - val_accuracy: 0.8842\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1835 - accuracy: 0.9393 - val_loss: 0.2756 - val_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1520 - accuracy: 0.9501 - val_loss: 0.2770 - val_accuracy: 0.8910\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.1233 - accuracy: 0.9617 - val_loss: 0.3243 - val_accuracy: 0.8760\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1054 - accuracy: 0.9676 - val_loss: 0.3073 - val_accuracy: 0.8847\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0893 - accuracy: 0.9733 - val_loss: 0.3321 - val_accuracy: 0.8826\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0743 - accuracy: 0.9789 - val_loss: 0.3465 - val_accuracy: 0.8832\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0642 - accuracy: 0.9815 - val_loss: 0.3712 - val_accuracy: 0.8817\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0522 - accuracy: 0.9864 - val_loss: 0.4496 - val_accuracy: 0.8670\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.0442 - accuracy: 0.9890 - val_loss: 0.4277 - val_accuracy: 0.8755\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0372 - accuracy: 0.9907 - val_loss: 0.4557 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.0299 - accuracy: 0.9930 - val_loss: 0.4981 - val_accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0223 - accuracy: 0.9961 - val_loss: 0.5960 - val_accuracy: 0.8589\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0209 - accuracy: 0.9959 - val_loss: 0.5635 - val_accuracy: 0.8690\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0165 - accuracy: 0.9967 - val_loss: 0.6097 - val_accuracy: 0.8667\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.6570 - val_accuracy: 0.8646\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.0097 - accuracy: 0.9988 - val_loss: 0.6775 - val_accuracy: 0.8657\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.7127 - val_accuracy: 0.8647\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "حالا بیایید سعی کنیم آن را با این مدل کوچکتر جایگزین کنیم.\n",
    "\n",
    "**نسخه مدل با ظرفیت کمتر**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 39ms/step - loss: 0.6335 - accuracy: 0.6718 - val_loss: 0.5572 - val_accuracy: 0.8392\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4979 - accuracy: 0.8705 - val_loss: 0.4605 - val_accuracy: 0.8616\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4028 - accuracy: 0.8945 - val_loss: 0.3909 - val_accuracy: 0.8737\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.3323 - accuracy: 0.9073 - val_loss: 0.3435 - val_accuracy: 0.8811\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2806 - accuracy: 0.9174 - val_loss: 0.3128 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2422 - accuracy: 0.9267 - val_loss: 0.2925 - val_accuracy: 0.8888\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2128 - accuracy: 0.9342 - val_loss: 0.2803 - val_accuracy: 0.8918\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1883 - accuracy: 0.9409 - val_loss: 0.2749 - val_accuracy: 0.8925\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1685 - accuracy: 0.9465 - val_loss: 0.2713 - val_accuracy: 0.8936\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1509 - accuracy: 0.9533 - val_loss: 0.2774 - val_accuracy: 0.8888\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1363 - accuracy: 0.9573 - val_loss: 0.2759 - val_accuracy: 0.8930\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.1234 - accuracy: 0.9629 - val_loss: 0.2798 - val_accuracy: 0.8907\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1116 - accuracy: 0.9663 - val_loss: 0.2863 - val_accuracy: 0.8911\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.1015 - accuracy: 0.9697 - val_loss: 0.2971 - val_accuracy: 0.8867\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0921 - accuracy: 0.9733 - val_loss: 0.3050 - val_accuracy: 0.8877\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.0835 - accuracy: 0.9762 - val_loss: 0.3155 - val_accuracy: 0.8858\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.0757 - accuracy: 0.9793 - val_loss: 0.3330 - val_accuracy: 0.8819\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0686 - accuracy: 0.9823 - val_loss: 0.3407 - val_accuracy: 0.8845\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.0622 - accuracy: 0.9839 - val_loss: 0.3570 - val_accuracy: 0.8800\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.0560 - accuracy: 0.9867 - val_loss: 0.3712 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Original model vs. smaller model on IMDB review classification](img/05-17.png)\n",
    "\n",
    "همانطور که می‌بینید، مدل کوچکتر دیرتر از مدل مرجع شروع به بیش‌برازش می‌کند (بعد از شش دوره به جای چهار)، و عملکرد آن با شروع بیش‌برازش برازش آهسته‌تر کاهش می‌یابد.\n",
    "\n",
    "اکنون، بیایید مدلی را بررسی خود اضافه کنیم که ظرفیت بسیار بیشتری دارد:\n",
    "    - اگر شکل خطاها فوراً شروع به بیش‌برازش کند و منحنی از خطای اعتبارسنجی با واریانس بالا متلاطم به نظر برسد، متوجه خواهید شد که مدل شما احتمالا خیلی بزرگ است. \n",
    "\n",
    "**نسخه مدل با ظرفیت بالاتر**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Original model vs. much larger model on IMDB review classification](img/05-18.png)\n",
    "\n",
    "مدل بزرگ‌تر تقریباً بلافاصله بعد از یک دوره، بیش‌برازش برازش می‌کند و خیلی شدیدتر می‌شود.\n",
    "- خطای اعتبارسنجی آن نیز نویزی‌تر است.\n",
    "- خیلی سریع خطای آموزش آن نزدیک به صفر می‌شود.\n",
    "    - هر چه مدل ظرفیت بیشتری داشته باشد، سریع‌تر می‌تواند داده‌های آموزشی را مدلسازی کند، اما بیشتر مستعد بیش‌برازش خواهد بود (در نتیجه تفاوت زیادی بین از دست دادن آموزش و اعتبارسنجی ایجاد می‌شود).\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### اضافه کردن تنظیم وزن\n",
    "\n",
    "- قاعده کلی: مدل‌های ساده‌تر نسبت به مدل‌های پیچیده، کمتر برازنده می‌شوند.\n",
    "\n",
    "یک _simple model_ در این زمینه مدلی است که در آن توزیع مقادیر پارامتر آنتروپی کمتری دارد  یا مدلی با پارامترهای کمتر).\n",
    "- یک راه متداول برای کاهش بیش‌برازش، اعمال محدودیت‌هایی بر پیچیدگی یک مدل با وادار کردن وزن‌های آن به گرفتن مقادیر کوچک است که توزیع مقادیر وزن‌ها را منظم‌تر می‌کند.\n",
    "- به این حالت تنظیم وزن ` weight regularization` می‌گویند و با اضافه کردن هزینه‌ای که با داشتن وزنه‌های بزرگ به تابع از دست دادن مدل اضافه می‌شود، انجام می‌شود.\n",
    "- این هزینه به دو صورت است:\n",
    "    * تنظیم هزینه اضافه شده متناسب با _مقدار مطلق ضرایب وزنی_ یا همان$L_1$ است .\n",
    "    * _$L_2$ regularization_ - هزینه اضافه شده متناسب با _square از مقدار ضرایب وزن است (_$L_2$ norm_ از وزن).\n",
    "\n",
    "    - منظم سازی $L_2$ در زمینه شبکه‌های عصبی _واپاشی وزنی_  `weight decay` نیز نامیده می‌شود.\n",
    "\n",
    "- در Keras، تنظیم وزن با ارسال _`weight regularizer`_ به لایه‌ها به صورت آرگومان‌های کلمه کلیدی انجام می‌شود.\n",
    "\n",
    "- مثال: تنظیم وزن $L_2$ را به مدل طبقه‌بندی بررسی فیلم اضافه می‌کنیم.\n",
    "\n",
    "**افزودن تنظیم وزن $L_2$ به مدل**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 50ms/step - loss: 0.5766 - accuracy: 0.7873 - val_loss: 0.4717 - val_accuracy: 0.8469\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3846 - accuracy: 0.8947 - val_loss: 0.3769 - val_accuracy: 0.8868\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.3199 - accuracy: 0.9171 - val_loss: 0.3633 - val_accuracy: 0.8876\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2886 - accuracy: 0.9271 - val_loss: 0.3702 - val_accuracy: 0.8804\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2720 - accuracy: 0.9327 - val_loss: 0.3812 - val_accuracy: 0.8746\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2542 - accuracy: 0.9417 - val_loss: 0.3682 - val_accuracy: 0.8833\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2449 - accuracy: 0.9448 - val_loss: 0.3642 - val_accuracy: 0.8867\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2377 - accuracy: 0.9464 - val_loss: 0.3699 - val_accuracy: 0.8843\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2299 - accuracy: 0.9485 - val_loss: 0.4038 - val_accuracy: 0.8713\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2258 - accuracy: 0.9504 - val_loss: 0.3950 - val_accuracy: 0.8755\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2197 - accuracy: 0.9555 - val_loss: 0.3878 - val_accuracy: 0.8777\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.2134 - accuracy: 0.9559 - val_loss: 0.4933 - val_accuracy: 0.8448\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.2124 - accuracy: 0.9577 - val_loss: 0.3946 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.2132 - accuracy: 0.9543 - val_loss: 0.4159 - val_accuracy: 0.8744\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.2120 - accuracy: 0.9557 - val_loss: 0.4028 - val_accuracy: 0.8764\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.2048 - accuracy: 0.9601 - val_loss: 0.4334 - val_accuracy: 0.8723\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 31ms/step - loss: 0.1994 - accuracy: 0.9634 - val_loss: 0.4178 - val_accuracy: 0.8740\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2065 - accuracy: 0.9565 - val_loss: 0.4111 - val_accuracy: 0.8771\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.1912 - accuracy: 0.9660 - val_loss: 0.4145 - val_accuracy: 0.8766\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1977 - accuracy: 0.9603 - val_loss: 0.4183 - val_accuracy: 0.8746\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مفهوم  0.002 به این معنی است که هر ضریب در ماتریس وزن لایه 0.002 نرم دوم آن وزن خطای کل مدل را اضافه می‌کند.\n",
    "- توجه داشته باشید که چون این جریمه _فقط در زمان تمرین اضافه می‌شود_ خطای این مدل در آموزش بسیار بیشتر از زمان تست خواهد بود.\n",
    "\n",
    "شکل زیر تأثیر جریمه تنظیم L2 را نشان می‌دهد.\n",
    "- همانطور که می‌بینید، مدل با تنظیم L2 نسبت به مدل مرجع بسیار مقاوم‌تر شده است، حتی اگر هر دو مدل تعداد پارامترهای یکسانی دارند.\n",
    "\n",
    "![Effect of L2 weight regularization on validation loss](img/05-19.png)\n",
    "\n",
    "به عنوان جایگزینی برای تنظیم وزن L2، می‌توانید از یکی از تنظیم کننده‌های وزن Keras زیر استفاده کنید.\n",
    "\n",
    "**تنظیم کننده‌های مختلف وزن موجود در کراس**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "توجه داشته باشید که تنظیم وزن بیشتر برای مدل‌های یادگیری عمیق کوچکتر استفاده می‌شود.  \n",
    "- مدل‌های یادگیری عمیق بزرگ آنقدر پارامتر دارد که اعمال محدودیت‌ بر مقادیر وزن تأثیر زیادی بر ظرفیت و تعمیم مدل ندارد.  \n",
    "- در این موارد، یک تکنیک چابک‌سازی متفاوت ترجیح داده می‌شود: `dropout`.  \n",
    "  \n",
    "#### اضافه کردن  `dropout`   \n",
    "  \n",
    "_Dropout_ یکی از موثرترین و پرکاربردترین تکنیک‌های منظم سازی برای شبکه‌های عصبی است.   \n",
    "    - توسط جف هینتون و دانشجویانش در دانشگاه تورنتو توسعه داده شد.  \n",
    "    - Dropout، اعمال شده بر روی یک لایه به طور تصادفی تعدادی از خروجی‌های آن را بر اساس نرخ مشخص شده صفر می‌کند.  \n",
    "    - نرخ `dropout` معمولا بین 0.2 و 0.5 تنظیم می‌شود.  \n",
    "    - تذکر: در زمان آزمون، هیچ واحدی صفر نمی‌شود.  \n",
    "         - در زمان آزمون در عمل تغییری در خروجی ایجاد نمی‌شود.   \n",
    "    - در عوض، مقادیر خروجی لایه با ضریبی برابر با نرخ انصراف کاهش می‌یابد، تا تعادل بیشتری نسبت به زمان آموزش فعال باشد.  \n",
    "  \n",
    "وجه داشته باشید که این فرآیند را می‌توان با انجام هر دو عملیات در زمان آموزش و بدون تغییر خروجی در زمان آزمایش، که اغلب به روشی که در عمل اجرا می‌شود، اجرا کرد (شکل 5.20 را ببینید)::  \n",
    "  \n",
    "`layer_output *= np.random.randint(0, high=2, size=layer_output.shape) layer_output /= 0.5`  \n",
    "  \n",
    "![Dropout applied to an activation matrix at training time, with rescaling happening during training. ](img/05-20.png)  \n",
    "  \n",
    "- ایده اصلی این است که وارد کردن نویز در مقادیر خروجی یک لایه می‌تواند الگوهای تصادفی را که مهم نیستند، از بین ببرد.  \n",
    "  \n",
    "در Keras، می‌توانید از طریق لایه Dropout که روی خروجی لایه درست قبل از آن اعمال می‌شود، dropout را در یک مدل معرفی کنید.  \n",
    "- بیایید دو لایه Dropout را در مدل IMDB اضافه کنیم تا ببینیم چقدر در کاهش بیش‌برازش مناسب عمل می‌کنند.  \n",
    "  \n",
    "**افزودن  `dropout`  به مدل IMDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![shows a plot of the results. ](img/05-21.png)\n",
    "\n",
    "- این یک پیشرفت واضح نسبت به مدل مرجع است - همچنین به نظر می‌رسد که بسیار بهتر از تنظیم L2 کار می‌کند، زیرا کمترین خطای اعتبارسنجی بهبود یافته است.\n",
    "\n",
    "![Effect of dropout on validation loss](img/05-21.png)\n",
    "\n",
    "- جمع بندی رایج‌ترین راه‌ها برای به حداکثر رساندن تعمیم و جلوگیری از بیش‌برازش در شبکه‌های عصبی:\n",
    "\n",
    "* داده‌های آموزشی بیشتر یا داده‌های آموزشی بهتر را دریافت کنید.\n",
    "* ویژگی‌های بهتر را توسعه دهید.\n",
    "* ظرفیت مدل را کاهش دهید.\n",
    "* اضافه کردن منظم وزن (برای مدل‌های کوچکتر).\n",
    "* اضافه کردن  `dropout` .\n",
    "\n",
    "## خلاصه\n",
    "* هدف یک مدل یادگیری ماشینی _تعمیم_سازی است: عملکرد دقیق روی ورودی‌هایی که قبلاً دیده نشده اند.\n",
    "- سخت تر از آن چیزی است که به نظر می‌رسد.\n",
    "* یک شبکه عصبی عمیق با یادگیری یک مدل پارامتریک به تعمیم دست می‌یابد که می‌تواند با موفقیت بین نمونه‌های آموزشی _ درون یابی_ کند - چنین مدلی می‌توان گفت که \"منیفولد نهفته\" داده‌های آموزشی را آموخته است.\n",
    "- به همین دلیل است که مدل‌های یادگیری عمیق فقط می‌توانند ورودی‌هایی را که بسیار نزدیک به آنچه در طول آموزش دیده‌اند معنا کنند.\n",
    "* مشکل اساسی در یادگیری ماشین، مصالحه بین بهینه‌سازی و تعمیم است: برای دستیابی به تعمیم، ابتدا باید به تطابق خوبی با داده‌های آموزشی دست یابید، اما این بهبود ناگزیر پس از مدتی به تعمیم آسیب می‌رساند.\n",
    "* توانایی تعمیم مدل‌های یادگیری عمیق از این واقعیت ناشی می‌شود که آنها موفق به یادگیری تقریبی منیفلد پنهان داده‌های خود می‌شوند و بنابراین می‌توانند ورودی‌های جدید را از طریق درون یابی معنا کنند.\n",
    "* این ضروری است که بتوانید قدرت تعمیم مدل خود را در حالی که در حال توسعه آن هستید به طور دقیق ارزیابی کنید.\n",
    "\n",
    "    - شما مجموعه‌ای از روش‌های ارزیابی را در اختیار دارید، از اعتبار سنجی ساده نگهدارنده تا اعتبارسنجی متقاطع K-fold و اعتبارسنجی متقاطع K-fold تکرار شده همراه با زدن.\n",
    "\n",
    "    - به خاطر داشته باشید که همیشه یک مجموعه آزمایشی کاملاً مجزا برای ارزیابی مدل نهایی داشته باشید، زیرا ممکن است اطلاعاتی از داده‌های اعتبارسنجی شما به مدل شما رخ داده باشد.\n",
    "* هنگامی که کار روی یک مدل را شروع می‌کنید، هدف شما ابتدا دستیابی به مدلی است که دارای قدرت تعمیم است و می‌تواند بیش‌برازش مناسب باشد.\n",
    "\n",
    "    - بهترین روش‌ها برای انجام این کار عبارتند از تنظیم میزان یادگیری و اندازه دسته‌ای، استفاده از اولویت‌های معماری بهتر، افزایش ظرفیت مدل، یا صرفاً آموزش طولانی‌تر.\n",
    "* همانطور که مدل شما شروع به تطبیق بیش‌برازش می‌کند، هدف شما به سمت بهبود تعمیم از طریق _`model regulation`_ تغییر می‌کند.\n",
    "\n",
    "    - می‌توانید ظرفیت مدل خود را کاهش دهید، کاهش وزن یا تنظیم وزن را اضافه کنید و از توقف زودهنگام استفاده کنید.\n",
    "\n",
    "    -  یک مجموعه داده بزرگتر یا بهتر همیشه راه شماره یک برای کمک به تعمیم یک مدل است.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
